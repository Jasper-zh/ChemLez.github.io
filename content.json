{"meta":{"title":"Liz'blog","subtitle":"","description":"","author":"Chemlez","url":"https://www.liizhi.cn","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-03-13T22:15:48.705Z","updated":"2020-03-12T14:05:20.867Z","comments":true,"path":"404.html","permalink":"https://www.liizhi.cn/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"关于","date":"2020-03-14T13:12:29.321Z","updated":"2020-03-14T13:12:29.321Z","comments":true,"path":"about/index.html","permalink":"https://www.liizhi.cn/about/index.html","excerpt":"","text":""},{"title":"友链","date":"2020-03-16T13:35:16.953Z","updated":"2020-03-16T13:03:29.630Z","comments":true,"path":"friends/index.html","permalink":"https://www.liizhi.cn/friends/index.html","excerpt":"左&nbsp邻&nbsp右&nbsp舍","text":"左&nbsp邻&nbsp右&nbsp舍 友链的话可以在下方留言，必须要有名称、头像链接、和至少一个标签哦～ 名称： Chemlez头像： https://s1.ax1x.com/2020/03/13/8mvbCj.jpg网址： https://liizhi.com标签： Java背景颜色参考： #87977F文字颜色参考： #EFEFEF"},{"title":"所有分类","date":"2020-03-14T13:13:15.519Z","updated":"2020-03-14T13:13:15.519Z","comments":true,"path":"categories/index.html","permalink":"https://www.liizhi.cn/categories/index.html","excerpt":"","text":""},{"title":"相册","slug":"photos","date":"2020-03-13T19:45:21.015Z","updated":"2019-08-24T06:40:38.000Z","comments":false,"path":"photos/index.html","permalink":"https://www.liizhi.cn/photos/index.html","excerpt":"","text":"Photos 图片正在加载中… (function() { var loadScript = function(path) { var $script = document.createElement('script') document.getElementsByTagName('body')[0].appendChild($script) $script.setAttribute('src', path) } setTimeout(function() { loadScript('./ins.js') }, 0) })()"},{"title":"","date":"2020-03-13T19:45:21.019Z","updated":"2019-10-04T12:54:50.000Z","comments":true,"path":"photos/data.json","permalink":"https://www.liizhi.cn/photos/data.json","excerpt":"","text":"{\"list\":[{\"date\":\"2019-9\",\"arr\":{\"year\":2019,\"month\":9,\"link\":[\"2019-9-14_晴空.jpg\",\"2019-9-14_晴空于校园.jpg\"],\"text\":[\"晴空\",\"晴空于校园\"],\"type\":[\"image\",\"image\"]}},{\"date\":\"2019-8\",\"arr\":{\"year\":2019,\"month\":8,\"link\":[\"2019-8-24_16年暑假某一傍晚拍摄于宁德海边.jpg\",\"2019-8-24_用于相册测试.jpg\"],\"text\":[\"16年暑假某一傍晚拍摄于宁德海边\",\"用于相册测试\"],\"type\":[\"image\",\"image\"]}}]}"},{"title":"","date":"2020-03-13T19:45:21.026Z","updated":"2019-08-24T07:36:08.000Z","comments":true,"path":"photos/ins.css","permalink":"https://www.liizhi.cn/photos/ins.css","excerpt":"","text":"#post-instagram{ padding: 30px; } #post-instagram .article-entry{ padding-right: 0; } .instagram{ position: relative; min-height: 500px; } .instagram img { width: 100%; } .instagram .year { font-size: 16px; } .instagram .open-ins{ padding: 10px 0; color: #cdcdcd; } .instagram .open-ins:hover{ color: #657b83; } .instagram .year{ display: inline; } .instagram .thumb { width: 25%; height: 0; padding-bottom: 25%; position: relative; display: inline-block; text-align: center; background: #ededed; outline: 1px solid #ddd; } .instagram .thumb a { position: relative; } .instagram .album h1 em{ font-style: normal; font-size: 14px; margin-left: 10px; } .instagram .album ul{ display: flex; flex-wrap: wrap; clear: both; width: 100%; text-align: left; } .instagram .album li{ list-style: none; display: inline-block; box-sizing: border-box; padding: 0 5px; margin-bottom: -10px; height: 0; width: 25%; position: relative; padding-bottom: 25%; } .instagram .album li:before{ display: none; } .instagram .album div.img-box{ position: absolute; width: 90%; height: 90%; -webkit-box-shadow: 0 1px 0 rgba(255,255,255,0.4), 0 1px 0 1px rgba(255,255,255,0.1); -moz-box-shadow: 0 1px 0 rgba(255,255,255,0.4), 0 1px 0 1px rgba(255,255,255,0.1); box-shadow: 0 1px 0 rgba(255,255,255,0.4), 0 1px 0 1px rgba(255,255,255,0.1); } .instagram .album div.img-box img{ width: 100%; height: 100%; position: absolute; z-index: 2; } .instagram .album div.img-box .img-bg{ position: absolute; top: 0; left: 0; bottom: 0px; width: 100%; margin: -5px; padding: 5px; -webkit-box-shadow: 0 0 0 1px rgba(0,0,0,.04), 0 1px 5px rgba(0,0,0,0.1); -moz-box-shadow: 0 0 0 1px rgba(0,0,0,.04), 0 1px 5px rgba(0,0,0,0.1); box-shadow: 0 0 0 1px rgba(0,0,0,.04), 0 1px 5px rgba(0,0,0,0.1); -webkit-transition: all 0.15s ease-out 0.1s; -moz-transition: all 0.15s ease-out 0.1s; -o-transition: all 0.15s ease-out 0.1s; transition: all 0.15s ease-out 0.1s; opacity: 0.2; cursor: pointer; display: block; z-index: 3; } .instagram .album div.img-box .icon { font-size: 14px; position: absolute; left: 50%; top: 50%; margin-left: -7px; margin-top: -7px; color: #999; z-index: 1; } .instagram .album div.img-box .img-bg:hover{ opacity: 0; } .photos-btn-wrap { border-bottom: 1px solid #e5e5e5; margin-bottom: 20px; } .photos-btn { font-size: 16px; color: #333; margin-bottom: -4px; padding: 5px 8px 3px; } .photos-btn.active { color: #08c; border: 1px solid #e5e5e5; border-bottom: 5px solid #fff; } @media screen and (max-width:600px) { .instagram .thumb { width: 50%; padding-bottom: 50%; } .instagram .album li { width: 100%; position: relative; padding-bottom: 100%; text-align: center; } .instagram .album div.img-box{ margin: 0; width: 90%; height: 90%; } } /* ====== video ===== */ .video-container { z-index: 1; position: relative; padding-bottom: 56.25%; margin: 0 auto; } .video-container iframe, .video-container object, .video-container embed { z-index: 1; position: absolute; top: 0; left: 7%; width: 85%; height: 85%; box-shadow: 0px 0px 20px 2px #888888; }"},{"title":"","date":"2020-03-13T19:45:21.013Z","updated":"2019-07-29T06:56:40.000Z","comments":true,"path":"photos/lazyload.min.js","permalink":"https://www.liizhi.cn/photos/lazyload.min.js","excerpt":"","text":"/*! * An jQuery | zepto plugin for lazy loading images. * author -> jieyou * see https://github.com/jieyou/lazyload * use some tuupola's code https://github.com/tuupola/jquery_lazyload (BSD) * use component's throttle https://github.com/component/throttle (MIT) */ !function(a){\"function\"==typeof define&&define.amd?define([\"jquery\"],a):a(window.jQuery||window.Zepto)}(function(a){function g(){}function h(a,b){var e;return e=b._$container==d?(\"innerHeight\"in c?c.innerHeight:d.height())+d.scrollTop():b._$container.offset().top+b._$container.height(),e=b.offset().left+e.threshold+b.width()}function l(a,b){var c=0;a.each(function(d){function g(){f.trigger(\"_lazyload_appear\"),c=0}var f=a.eq(d);if(!(f.width()b.failure_limit)return!1}else g()})}function m(a){return a.filter(function(b){return!a.eq(b)._lazyload_loadStarted})}function n(a,b){function h(){f=0,g=+new Date,e=a.apply(c,d),c=null,d=null}var c,d,e,f,g=0;return function(){c=this,d=arguments;var a=new Date-g;return f||(a>=b?h():f=setTimeout(h,b-a)),e}}var f,c=window,d=a(c),e={threshold:0,failure_limit:0,event:\"scroll\",effect:\"show\",effect_params:null,container:c,data_attribute:\"original\",data_srcset_attribute:\"original-srcset\",skip_invisible:!0,appear:g,load:g,vertical_only:!1,check_appear_throttle_time:300,url_rewriter_fn:g,no_fake_img_loader:!1,placeholder_data_img:\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsQAAA7EAZUrDhsAAAANSURBVBhXYzh8+PB/AAffA0nNPuCLAAAAAElFTkSuQmCC\",placeholder_real_img:\"http://ditu.baidu.cn/yyfm/lazyload/0.0.1/img/placeholder.png\"};f=function(){var a=Object.prototype.toString;return function(b){return a.call(b).replace(\"[object \",\"\").replace(\"]\",\"\")}}(),a.fn.hasOwnProperty(\"lazyload\")||(a.fn.lazyload=function(b){var i,j,k,h=this;return a.isPlainObject(b)||(b={}),a.each(e,function(g,h){var i=f(b[g]);-1!=a.inArray(g,[\"threshold\",\"failure_limit\",\"check_appear_throttle_time\"])?\"String\"==i?b[g]=parseInt(b[g],10):\"Number\"!=i&&(b[g]=h):\"container\"==g?(b._$container=b.hasOwnProperty(g)?b[g]==c||b[g]==document?d:a(b[g]):d,delete b.container):!e.hasOwnProperty(g)||b.hasOwnProperty(g)&&i==f(e[g])||(b[g]=h)}),i=\"scroll\"==b.event,k=0==b.check_appear_throttle_time?l:n(l,b.check_appear_throttle_time),j=i||\"scrollstart\"==b.event||\"scrollstop\"==b.event,h.each(function(c){var e=this,f=h.eq(c),i=f.attr(\"src\"),k=f.attr(\"data-\"+b.data_attribute),l=b.url_rewriter_fn==g?k:b.url_rewriter_fn.call(e,f,k),n=f.attr(\"data-\"+b.data_srcset_attribute),o=f.is(\"img\");return 1==f._lazyload_loadStarted||i==l?(f._lazyload_loadStarted=!0,h=m(h),void 0):(f._lazyload_loadStarted=!1,o&&!i&&f.one(\"error\",function(){f.attr(\"src\",b.placeholder_real_img)}).attr(\"src\",b.placeholder_data_img),f.one(\"_lazyload_appear\",function(){function i(){d&&f.hide(),o?(n&&f.attr(\"srcset\",n),l&&f.attr(\"src\",l)):f.css(\"background-image\",'url(\"'+l+'\")'),d&&f[b.effect].apply(f,c?b.effect_params:[]),h=m(h)}var d,c=a.isArray(b.effect_params);f._lazyload_loadStarted||(d=\"show\"!=b.effect&&a.fn[b.effect]&&(!b.effect_params||c&&0==b.effect_params.length),b.appear!=g&&b.appear.call(e,f,h.length,b),f._lazyload_loadStarted=!0,b.no_fake_img_loader||n?(b.load!=g&&f.one(\"load\",function(){b.load.call(e,f,h.length,b)}),i()):a(\"\").one(\"load\",function(){i(),b.load!=g&&b.load.call(e,f,h.length,b)}).attr(\"src\",l))}),j||f.on(b.event,function(){f._lazyload_loadStarted||f.trigger(\"_lazyload_appear\")}),void 0)}),j&&b._$container.on(b.event,function(){k(h,b)}),d.on(\"resize load\",function(){k(h,b)}),a(function(){k(h,b)}),this})});"},{"title":"","date":"2020-03-13T19:45:21.017Z","updated":"2019-08-29T07:01:20.000Z","comments":true,"path":"photos/ins.js","permalink":"https://www.liizhi.cn/photos/ins.js","excerpt":"","text":"/******/ (function(modules) { // webpackBootstrap /******/ // The module cache /******/ var installedModules = {}; /******/ /******/ // The require function /******/ function __webpack_require__(moduleId) { /******/ /******/ // Check if module is in cache /******/ if (installedModules[moduleId]) /******/ return installedModules[moduleId].exports; /******/ /******/ // Create a new module (and put it into the cache) /******/ var module = installedModules[moduleId] = { /******/ exports: {}, /******/ id: moduleId, /******/ loaded: false /******/ }; /******/ /******/ // Execute the module function /******/ modules[moduleId].call(module.exports, module, module.exports, __webpack_require__); /******/ /******/ // Flag the module as loaded /******/ module.loaded = true; /******/ /******/ // Return the exports of the module /******/ return module.exports; /******/ } /******/ /******/ /******/ // expose the modules object (__webpack_modules__) /******/ __webpack_require__.m = modules; /******/ /******/ // expose the module cache /******/ __webpack_require__.c = installedModules; /******/ /******/ // __webpack_public_path__ /******/ __webpack_require__.p = \"/dist/\"; /******/ /******/ // Load entry module and return exports /******/ return __webpack_require__(0); /******/ }) /************************************************************************/ /******/ ([ /* 0 */ /***/ function(module, exports, __webpack_require__) { 'use strict'; __webpack_require__(1); var _view = __webpack_require__(2); var _view2 = _interopRequireDefault(_view); function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; } /** * @name impush-client * @description 这个项目让我发家致富… * @date 2016-12-1 */ var _collection = []; var _count = 0; var searchData; function addMask(elem) { var rect = elem.getBoundingClientRect(); var style = getComputedStyle(elem, null); var mask = document.createElement('i'); mask.className = 'icon-film'; mask.style.color = '#fff'; mask.style.fontSize = '26px'; mask.style.position = 'absolute'; mask.style.right = '10px'; mask.style.bottom = '10px'; mask.style.zIndex = 1; elem.parentNode.appendChild(mask); } var createVideoIncon = function createVideoIncon() { var $videoImg = document.querySelectorAll('.thumb a[data-type=\"video\"]'); for (var i = 0, len = $videoImg.length; i < len; i++) { addMask($videoImg[i]); } }; // 修改这里render()函数：修改图片的路径地址.minSrc 小图的路径. src 大图的路径.修改为自己的图片路径(github的路径) // https://raw.githubusercontent.com/ChemLez/blog-Picture/master/photos/ // https://raw.githubusercontent.com/ChemLez/blog-Picture/master/min_photos/ var render = function render(res) { var ulTmpl = \"\"; for (var j = 0, len2 = res.list.length; j < len2; j++) { var data = res.list[j].arr; var liTmpl = \"\"; for (var i = 0, len = data.link.length; i < len; i++) { var minSrc = 'https://raw.githubusercontent.com/ChemLez/blog-Picture/master/min_photos/' + data.link[i]; var src = 'https://raw.githubusercontent.com/ChemLez/blog-Picture/master/photos/' + data.link[i]; var type = data.type[i]; var target = src + (type === 'video' ? '.mp4' : '.jpg'); src += ''; liTmpl += '\\ \\ \\ \\ ' + data.text[i] + '\\ '; } ulTmpl = ulTmpl + '' + data.year + '年' + data.month + '月\\ ' + liTmpl + '\\ '; } document.querySelector('.instagram').innerHTML = '' + ulTmpl + ''; createVideoIncon(); _view2.default.init(); }; var replacer = function replacer(str) { var arr = str.split(\"/\"); return \"/assets/ins/\" + arr[arr.length - 1]; }; var ctrler = function ctrler(data) { var imgObj = {}; for (var i = 0, len = data.length; i < len; i++) { var y = data[i].y; var m = data[i].m; var src = replacer(data[i].src); var text = data[i].text; var key = y + \"\" + ((m + \"\").length == 1 ? \"0\" + m : m); if (imgObj[key]) { imgObj[key].srclist.push(src); imgObj[key].text.push(text); } else { imgObj[key] = { year: y, month: m, srclist: [src], text: [text] }; } } render(imgObj); }; function loadData(success) { if (!searchData) { var xhr = new XMLHttpRequest(); xhr.open('GET', './data.json?t=' + +new Date(), true); xhr.onload = function() { if (this.status >= 200 && this.status < 300) { var res = JSON.parse(this.response); searchData = res; success(searchData); } else { console.error(this.statusText); } }; xhr.onerror = function() { console.error(this.statusText); }; xhr.send(); } else { success(searchData); } } var Ins = { init: function init() { loadData(function(data) { render(data); }); } }; Ins.init(); // export default impush; /***/ }, /* 1 */ /***/ function(module, exports, __webpack_require__) { /* WEBPACK VAR INJECTION */ (function(global) { 'use strict'; var inViewport = __webpack_require__(3); var lazyAttrs = ['data-src']; global.lzld = lazyload(); // Provide libs using getAttribute early to get the good src // and not the fake data-src replaceGetAttribute('Image'); replaceGetAttribute('IFrame'); function registerLazyAttr(attr) { if (indexOf.call(lazyAttrs, attr) === -1) { lazyAttrs.push(attr); } } function lazyload(opts) { opts = merge({ 'offset': 333, 'src': 'data-src', 'container': false }, opts || {}); if (typeof opts.src === 'string') { registerLazyAttr(opts.src); } var elts = []; function show(elt) { var src = findRealSrc(elt); if (src) { elt.src = src; } elt.setAttribute('data-lzled', true); elts[indexOf.call(elts, elt)] = null; } function findRealSrc(elt) { if (typeof opts.src === 'function') { return opts.src(elt); } return elt.getAttribute(opts.src); } function register(elt) { elt.onload = null; elt.removeAttribute('onload'); elt.onerror = null; elt.removeAttribute('onerror'); if (indexOf.call(elts, elt) === -1) { inViewport(elt, opts, show); } } return register; } function replaceGetAttribute(elementName) { var fullname = 'HTML' + elementName + 'Element'; if (fullname in global === false) { return; } var original = global[fullname].prototype.getAttribute; global[fullname].prototype.getAttribute = function(name) { if (name === 'src') { var realSrc; for (var i = 0, max = lazyAttrs.length; i < max; i++) { realSrc = original.call(this, lazyAttrs[i]); if (realSrc) { break; } } return realSrc || original.call(this, name); } // our own lazyloader will go through theses lines // because we use getAttribute(opts.src) return original.call(this, name); }; } function merge(defaults, opts) { for (var name in defaults) { if (opts[name] === undefined) { opts[name] = defaults[name]; } } return opts; } // http://webreflection.blogspot.fr/2011/06/partial-polyfills.html function indexOf(value) { for (var i = this.length; i-- && this[i] !== value;) {} return i; } module.exports = lazyload; // export default impush; /* WEBPACK VAR INJECTION */ }.call(exports, (function() { return this; }()))) /***/ }, /* 2 */ /***/ function(module, exports) { 'use strict'; var initPhotoSwipeFromDOM = function initPhotoSwipeFromDOM(gallerySelector) { // parse slide data (url, title, size ...) from DOM elements // (children of gallerySelector) var parseThumbnailElements = function parseThumbnailElements(el) { el = el.parentNode.parentNode; var thumbElements = el.getElementsByClassName('thumb'), numNodes = thumbElements.length, items = [], figureEl, linkEl, size, type, // video or not target, item; for (var i = 0; i < numNodes; i++) { figureEl = thumbElements[i]; // // include only element nodes if (figureEl.nodeType !== 1) { continue; } linkEl = figureEl.children[0]; // size = linkEl.getAttribute('data-size').split('x'); type = linkEl.getAttribute('data-type'); target = linkEl.getAttribute('data-target'); // create slide object item = { src: linkEl.getAttribute('href'), w: parseInt(size[0], 10), h: parseInt(size[1], 10) }; if (figureEl.children.length > 1) { item.title = figureEl.children[1].innerHTML; } if (linkEl.children.length > 0) { item.msrc = linkEl.children[0].getAttribute('src'); item.type = type; item.target = target; item.html = ''; if (type === 'video') { //item.src = null; } } item.el = figureEl; // save link to element for getThumbBoundsFn items.push(item); } return items; }; // find nearest parent element var closest = function closest(el, fn) { return el && (fn(el) ? el : closest(el.parentNode, fn)); }; // triggers when user clicks on thumbnail var onThumbnailsClick = function onThumbnailsClick(e) { e = e || window.event; e.preventDefault ? e.preventDefault() : e.returnValue = false; var eTarget = e.target || e.srcElement; // find root element of slide var clickedListItem = closest(eTarget, function(el) { return el.tagName && el.tagName.toUpperCase() === 'FIGURE'; }); if (!clickedListItem) { return; } // find index of clicked item by looping through all child nodes // alternatively, you may define index via data- attribute var clickedGallery = clickedListItem.parentNode, // childNodes = clickedListItem.parentNode.childNodes, // numChildNodes = childNodes.length, childNodes = document.getElementsByClassName('thumb'), numChildNodes = childNodes.length, nodeIndex = 0, index; for (var i = 0; i < numChildNodes; i++) { if (childNodes[i].nodeType !== 1) { continue; } if (childNodes[i] === clickedListItem) { index = nodeIndex; break; } nodeIndex++; } if (index >= 0) { // open PhotoSwipe if valid index found openPhotoSwipe(index, clickedGallery); } return false; }; // parse picture index and gallery index from URL (#&pid=1&gid=2) var photoswipeParseHash = function photoswipeParseHash() { var hash = window.location.hash.substring(1), params = {}; if (hash.length < 5) { return params; } var vars = hash.split('&'); for (var i = 0; i < vars.length; i++) { if (!vars[i]) { continue; } var pair = vars[i].split('='); if (pair.length < 2) { continue; } params[pair[0]] = pair[1]; } if (params.gid) { params.gid = parseInt(params.gid, 10); } return params; }; var openPhotoSwipe = function openPhotoSwipe(index, galleryElement, disableAnimation, fromURL) { var pswpElement = document.querySelectorAll('.pswp')[0], gallery, options, items; items = parseThumbnailElements(galleryElement); // define options (if needed) options = { // define gallery index (for URL) galleryUID: galleryElement.getAttribute('data-pswp-uid'), getThumbBoundsFn: function getThumbBoundsFn(index) { // See Options -> getThumbBoundsFn section of documentation for more info var thumbnail = items[index].el.getElementsByTagName('img')[0], // find thumbnail pageYScroll = window.pageYOffset || document.documentElement.scrollTop, rect = thumbnail.getBoundingClientRect(); return { x: rect.left, y: rect.top + pageYScroll, w: rect.width }; } }; // PhotoSwipe opened from URL if (fromURL) { if (options.galleryPIDs) { // parse real index when custom PIDs are used // http://photoswipe.com/documentation/faq.html#custom-pid-in-url for (var j = 0; j < items.length; j++) { if (items[j].pid == index) { options.index = j; break; } } } else { // in URL indexes start from 1 options.index = parseInt(index, 10) - 1; } } else { options.index = parseInt(index, 10); } // exit if index not found if (isNaN(options.index)) { return; } if (disableAnimation) { options.showAnimationDuration = 0; } // Pass data to PhotoSwipe and initialize it gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, options); gallery.init(); var $tempVideo; var stopVideoHandle = function stopVideoHandle() { if ($tempVideo) { $tempVideo.remove(); $tempVideo = null; } }; var changeHandle = function changeHandle() { var item = gallery.currItem; stopVideoHandle(); if (item.type === 'video') { var $ctn = item.container; var style = $ctn.getElementsByClassName('pswp__img')[0].style; var $video = document.createElement('video'); $video.setAttribute('autoplay', 'autoplay'); $video.setAttribute('controls', 'controls'); $video.setAttribute('src', item.target); $video.style.width = style.width; $video.style.height = style.height; $video.style.position = 'absolute'; $video.style.zIndex = 2; $tempVideo = $video; $ctn.appendChild($video); } }; gallery.listen('initialZoomIn', changeHandle); gallery.listen('afterChange', changeHandle); gallery.listen('initialZoomOut', stopVideoHandle); }; // loop through all gallery elements and bind events var galleryElements = document.querySelectorAll(gallerySelector); for (var i = 0, l = galleryElements.length; i < l; i++) { galleryElements[i].setAttribute('data-pswp-uid', i + 1); galleryElements[i].onclick = onThumbnailsClick; } // Parse URL and open gallery if it contains #&pid=3&gid=1 var hashData = photoswipeParseHash(); if (hashData.pid && hashData.gid) { openPhotoSwipe(hashData.pid, galleryElements[hashData.gid - 1], true, true); } }; var Viewer = function() { function init() { initPhotoSwipeFromDOM('.photos'); } return { init: init }; }(); module.exports = Viewer; /***/ }, /* 3 */ /***/ function(module, exports) { /* WEBPACK VAR INJECTION */ (function(global) { module.exports = inViewport; var instances = []; var supportsMutationObserver = typeof global.MutationObserver === 'function'; function inViewport(elt, params, cb) { var opts = { container: global.document.body, offset: 0 }; if (params === undefined || typeof params === 'function') { cb = params; params = {}; } var container = opts.container = params.container || opts.container; var offset = opts.offset = params.offset || opts.offset; for (var i = 0; i < instances.length; i++) { if (instances[i].container === container) { return instances[i].isInViewport(elt, offset, cb); } } return instances[ instances.push(createInViewport(container)) - 1 ].isInViewport(elt, offset, cb); } function addEvent(el, type, fn) { if (el.attachEvent) { el.attachEvent('on' + type, fn); } else { el.addEventListener(type, fn, false); } } function debounce(func, wait, immediate) { var timeout; return function() { var context = this, args = arguments; var callNow = immediate && !timeout; clearTimeout(timeout); timeout = setTimeout(later, wait); if (callNow) func.apply(context, args); function later() { timeout = null; if (!immediate) func.apply(context, args); } }; } // https://github.com/jquery/sizzle/blob/3136f48b90e3edc84cbaaa6f6f7734ef03775a07/sizzle.js#L708 var contains = function() { if (!global.document) { return true; } return global.document.documentElement.compareDocumentPosition ? function(a, b) { return !!(a.compareDocumentPosition(b) & 16); } : global.document.documentElement.contains ? function(a, b) { return a !== b && (a.contains ? a.contains(b) : false); } : function(a, b) { while (b = b.parentNode) { if (b === a) { return true; } } return false; }; } function createInViewport(container) { var watches = createWatches(); var scrollContainer = container === global.document.body ? global : container; var debouncedCheck = debounce(watches.checkAll(watchInViewport), 15); addEvent(scrollContainer, 'scroll', debouncedCheck); if (scrollContainer === global) { addEvent(global, 'resize', debouncedCheck); } if (supportsMutationObserver) { observeDOM(watches, container, debouncedCheck); } // failsafe check, every 200ms we check for visible images // usecase: a hidden parent containing eleements // when the parent becomes visible, we have no event that the children // became visible setInterval(debouncedCheck, 150); function isInViewport(elt, offset, cb) { if (!cb) { return isVisible(elt, offset); } var remote = createRemote(elt, offset, cb); remote.watch(); return remote; } function createRemote(elt, offset, cb) { function watch() { watches.add(elt, offset, cb); } function dispose() { watches.remove(elt); } return { watch: watch, dispose: dispose }; } function watchInViewport(elt, offset, cb) { if (isVisible(elt, offset)) { watches.remove(elt); cb(elt); } } function isVisible(elt, offset) { if (!contains(global.document.documentElement, elt) || !contains(global.document.documentElement, container)) { return false; } // Check if the element is visible // https://github.com/jquery/jquery/blob/740e190223d19a114d5373758127285d14d6b71e/src/css/hiddenVisibleSelectors.js if (!elt.offsetWidth || !elt.offsetHeight) { return false; } var eltRect = elt.getBoundingClientRect(); var viewport = {}; if (container === global.document.body) { viewport = { top: -offset, left: -offset, right: global.document.documentElement.clientWidth + offset, bottom: global.document.documentElement.clientHeight + offset }; } else { var containerRect = container.getBoundingClientRect(); viewport = { top: containerRect.top - offset, left: containerRect.left - offset, right: containerRect.right + offset, bottom: containerRect.bottom + offset }; } // The element must overlap with the visible part of the viewport var visible = ( (eltRect.right > viewport.left) && (eltRect.left < viewport.right) && (eltRect.bottom > viewport.top) && (eltRect.top < viewport.bottom) ); return visible; } return { container: container, isInViewport: isInViewport }; } function createWatches() { var watches = []; function add(elt, offset, cb) { if (!isWatched(elt)) { watches.push([elt, offset, cb]); } } function remove(elt) { var pos = indexOf(elt); if (pos !== -1) { watches.splice(pos, 1); } } function indexOf(elt) { for (var i = watches.length - 1; i >= 0; i--) { if (watches[i][0] === elt) { return i; } } return -1; } function isWatched(elt) { return indexOf(elt) !== -1; } function checkAll(cb) { return function() { for (var i = watches.length - 1; i >= 0; i--) { cb.apply(this, watches[i]); } }; } return { add: add, remove: remove, isWatched: isWatched, checkAll: checkAll }; } function observeDOM(watches, container, cb) { var observer = new MutationObserver(watch); var filter = Array.prototype.filter; var concat = Array.prototype.concat; observer.observe(container, { childList: true, subtree: true, // changes like style/width/height/display will be catched attributes: true }); function watch(mutations) { // some new DOM nodes where previously watched // we should check their positions if (mutations.some(knownNodes) === true) { setTimeout(cb, 0); } } function knownNodes(mutation) { var nodes = concat.call([], Array.prototype.slice.call(mutation.addedNodes), mutation.target ); return filter.call(nodes, watches.isWatched).length > 0; } } /* WEBPACK VAR INJECTION */ }.call(exports, (function() { return this; }()))) /***/ } /******/ ]);"},{"title":"相册","slug":"photos","date":"2020-03-13T19:45:21.022Z","updated":"2019-08-24T07:36:10.000Z","comments":true,"path":"photos/videos.html","permalink":"https://www.liizhi.cn/photos/videos.html","excerpt":"","text":"Photos Videos 指弹_女儿情 指弹_友谊地久天长 指弹_Always with me"},{"title":"","date":"2020-03-16T12:31:07.241Z","updated":"2020-03-12T14:01:14.183Z","comments":true,"path":"mylist/index.html","permalink":"https://www.liizhi.cn/mylist/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-03-14T13:11:57.988Z","updated":"2020-03-14T13:11:57.988Z","comments":true,"path":"tags/index.html","permalink":"https://www.liizhi.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Python爬虫基础入门","slug":"Python爬虫基础入门","date":"2020-03-18T09:30:11.000Z","updated":"2020-03-18T09:38:27.749Z","comments":true,"path":"2020/03/18/Python爬虫基础入门/","link":"","permalink":"https://www.liizhi.cn/2020/03/18/Python%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/","excerpt":"","text":"一、Requests库的7个主要方法 方法 说明 requests.request() 构造一个请求，支撑一下各方法的基础方法 requests.get() 获取HTML网页的主要方法，对应于HTTP的GET requests.head() 获取HTML网页头信息的方法，对应于HTTP的HEAD requests.post() 向HTML网页提交POST请求的方法，对应于HTTP的POST requests.put() 向HTML网页提交PUT请求的方法，对应于HTTP的PUT requests.pathch() 向HTML网页提交局部修改请求，对应于HTTP的PATCH requests.delete() 向HTML页面提交删除请求，对应于HTTP的DELETE 1.requests.getr = requests.get(url) 返回一个包含服务器资源的Response对象，包含爬虫返回的全部内容 构造一个向服务器请求资源的Request对象 requests.get(url,params=None,**kwargs) url:拟获取网页的url链接 params:url中的额外参数，字典或字节流格式，可选 **kwargs:12个控制访问的参数 2.Response对象的属性 属性 说明 r.status_code HTTP请求的返回状态，200表示连接成功，404表示失败 r.text HTTP响应内容的字符串形式，即，url对应的页面内容 r.encoding 从HTTP header中猜测的响应内容编码方式 r.apparent_encoding 从内容中分析出的响应内容编码方式（备选编码方式） r.content HTTP响应的二进制形式 r.encoding:如果header中不存在charset，则认为编码为ISO-8859-1 r.apparent_encoding:根据网页内容分析出的编码方式 3.理解Requests库的异常 异常 说明 requests.ConnectionError 网络连接错误异常，如DNS查询失败、拒绝连接等 requests.HTTPError HTTP错误异常 requests.TooManyRedirects 超过最大重定向次数，产生重定向异常 requests.ConnectTimeout 连接远程服务器时异常 requests.URLRequired URL缺失异常 Requests.Timeout 请求URL超时，产生超时异常 异常 说明 r.raise_for_status 如果不是200，产生异常requests.HTTPError 爬取网页的通用代码框架12345678910111213import requestsdef getHTMLText(url): try: r = requests.get(url,timeout=30) r.raise_for_status() # 如果状态不是200，引发HTTPError异常 r.encoding = r.apparent_encoding return r.text except: return '产生异常'if __name__ == '__main__': url = 'http://www.baidu.com' print(getHTMLText(url)) 二、HTTP协议HTTP，Hypertext Transfer Protocol,超文本传输协议。 HTTP是一个基于”请求与响应“模式的、无状态的应用层协议。 无状态：第一次请求与第二次请求无关联 HTTP协议采用URL作为定位网络资源的标识。 URL格式 http://host[:port][path] host:合法的Internet主机域名或IP地址 port:端口号，缺省端口为80 path:请求资源的路径 HTTP URL的理解 URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源。 1.HTTP协议对资源的操作 方法 说明 GET 请求获取URL位置的资源 HEAD 请求获取URL位置资源的响应消息报告，即获得该资源的头部信息 POST 请求向URL位置的资源后附新的数据 PUT 请求向URL位置存储一个资源，覆盖原URL PATCH 请求局部更新URL位置的资源，即改变该处资源的部分内容 DELETE 请求删除URL位置存储的资源 2.理解PATCH和PUT的区别假设URL位置有一组数据UserInfo,包括UserID、UserName等20个字段。 需求：用户修改了UserName,其他不变。 采用PATCH,仅向URL提交UserName的局部更新请求。 采用PUT，必须将所有20个字段一并提交到URL，未提交字段被删除。 PATCH的最主要好处：节省网络带宽 三、Requests库的7个主要方法解析1.requests.request()requests.request(method,url,**kwargs) method：请求方式。 ‘GET’、’HEAD’、’POST’、’PUT’、’PATCH’、’delete’、’OPTIONS’ **kwargs:控制访问的参数，均为可选项。 params:字典或字节序列，作为参数增加到url中。 data：字典、字节序列对象，重点是向服务器提交资源时使用。 json:JSON格式的数据，作为request的内容。 headers:字典，HTTP定制头。 cookies:字典或CookieJar,Request中的cookie。 auth:元祖，支持HTTP认证功能。 files:字典类型，传输文件。 timeout:设定超时时间，秒为单位。 proxies:字典类型，设定访问代理服务器，可以增加登录认证。 allow_redirects:True/False,默认为True，重定向开关。 stream:True/False,默认为True，获取内容立即下载开关。 verify:True/False,默认为True，认证SSL证书开关。 cert:本地SSL证书路径。 四、Beautiful Soup库使用1.BeautifulSoup 基本使用12from bs4 import BeautifulSoupsoup = BeautifulSoup('&lt;p&gt;data&lt;/p&gt;','html.parser') # 第一个参数为html文本内容，对html标签进行解析 2.Beautiful Soup库理解Beautiful Soup库,也叫做 beautifulsoup4或bs4, 是解析、变量、维护”标签树“的功能库。只要提供的文件是标签类型，Beautiful Soup库都可以用来解析。 因为文档和标签树是一一对应的，标签树经过Beautiful Soup，转换为Beautiful Soup类型。故，文档和标签树以及Beautiful Soup是一一对应关系。 123from bs4 import BeautifulSoupsoup = BeautifulSoup('&lt;p&gt;data&lt;/p&gt;','html.parser')soup2 = BeautifulSoup(open(\"D://demo.html\",'html.parser') Beautiful Soup对应一个HTML/XML文档的全部内容。 3.Beautiful Soup库解析器 解析器 使用方法 条件 bs的HTML解析器 BeautifulSoup(mk,’html.parser’) 安装bs4库 lxml的HTML解析器 BeautifulSoup(mk,’lxml’) pip install lxml lxml的XML解析器 BeautifulSoup(mk,’xml’) pip install lxml html5lib的解析器 BeautifulSoup(mk,’htlm5lib’) pip install html5lib 4.Beautiful Soup类的基本元素 基本元素 说明 Tag 标签，最基本的信息组织单元，分别用&lt;&gt;和&lt;/&gt;表面开头和结尾 Name 标签的名称，…的名字是’p’，格式：.name Attributes 标签的属性，字典形式组织，格式：.attrs NavigableString 标签内非属性字符串，&lt;&gt;…&lt;/&gt;中字符串，格式：.string Comment 标签内字符串的注释部分，一种特殊的Comment类型 123456789101112131415161718192021222324252627282930313233343536373839404142434445import requestsr = requests.get('http://python123.io/ws/demo.html')demo = r.text # demo为标签文本&gt;'&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;\\r\\n&lt;body&gt;\\r\\n&lt;p class=\"title\"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;\\r\\n&lt;p class=\"course\"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\r\\n&lt;a href=\"http://www.icourse163.org/course/BIT-268001\" class=\"py1\" id=\"link1\"&gt;Basic Python&lt;/a&gt; and &lt;a href=\"http://www.icourse163.org/course/BIT-1001870001\" class=\"py2\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;\\r\\n&lt;/body&gt;&lt;/html&gt;'# 利用BeautifulSoup 解析成标签树from bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser')soup&gt;[out]:&lt;html&gt;&lt;head&gt;&lt;title&gt;This is a python demo page&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=\"title\"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;&lt;p class=\"course\"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:&lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt; and &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;print(soup.prettify()) # 输出标签树 &gt;[out]:&lt;html&gt; &lt;head&gt; &lt;title&gt; This is a python demo page &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=\"title\"&gt; &lt;b&gt; The demo python introduces several python courses. &lt;/b&gt; &lt;/p&gt; &lt;p class=\"course\"&gt; Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses: &lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt; Basic Python &lt;/a&gt; and &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt; Advanced Python &lt;/a&gt; . &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 实例一 Tag 12345678910111213# 任何标签都可直接用soup.&lt;标签&gt;将其取出,当文本中存在多个相同标签时，其返回的为第一个import requestsr = requests.get('http://python123.io/ws/demo.html')demo = r.text # demo为标签文本from bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser') # 解析的页面实例soup.title # 标签&gt; &lt;title&gt;This is a python demo page&lt;/title&gt;tag = soup.a tag&gt; &lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt; 实例二 Name 123456789101112# 获取标签名称方法 &lt;tag&gt;.nameimport requestsr = requests.get('http://python123.io/ws/demo.html')demo = r.text # demo为标签文本from bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser') # 解析的页面实例soup.a.name&gt; 'a'soup.a.parent.name # a的上一层标签,即父标签&gt; 'p' 实例三 Attributes 123456789101112131415161718# 获取标签的属性 &lt;tag&gt;.attrsimport requestsr = requests.get('http://python123.io/ws/demo.html')demo = r.text # demo为标签文本from bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser') # 解析的页面实例tag = souo.a # 取a标签attrs = soup.attrs # 提取出a标签的属性&gt; &#123;'href': 'http://www.icourse163.org/course/BIT-268001', 'class': ['py1'], 'id': 'link1'&#125;# ，可以从结果看出，是字典的形式，故可直接通过键-值对的形式进一步提取信息内容attrs['id']&gt; 'link1'attrs['href']&gt; 'http://www.icourse163.org/course/BIT-268001' 实例四 NavigableString 123456789101112# 获取标签的属性 &lt;tag&gt;.string 用于取出标签之间的字符串import requestsr = requests.get('http://python123.io/ws/demo.html')demo = r.text # demo为标签文本from bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser') # 解析的页面实例soup.a.string&gt; 'Basic Python'soup.p.string&gt; 'The demo python introduces several python courses.' （可跨越标签层次） 实例五 判断注释 123456789101112# 获取标签的属性 &lt;tag&gt;.string 用于取出标签之间的字符串soup = BeautifulSoup(\"&lt;b&gt;&lt;! --This is a comment--&gt;&lt;/b&gt;&lt;p&gt;This is not a comment&lt;/p&gt;\",'html.parser')soup.b.string&gt; 'This is not a comment'type(soup.b.string)&gt; bs4.element.Commentsoup.p.string&gt; 'This is not a comment'type(soup.p.string)&gt; bs4.element.NavigableString# 两者的类型不同，来判断是否为注释 5.基于Beautiful Soup HTML的遍历方法遍历方法：标签树，其为树形结构。 下行遍历 上行遍历 平行遍历 5.1 下行遍历 属性 说明 .contents 子节点的列表，将所有儿子节点存入列表 （返回列表类型） .children 子节点的迭代类型，与.contents类似，用于循环遍历儿子节点 （返回迭代类型） .descendants 子孙节点的迭代类型，包含所有子孙节点，用于循环遍历 （同上） 本小结实例皆以代码作为开头，不再重复写 &gt;代表输出 123456import requestsr = requests.get('http://python123.io/ws/demo.html')demo = r.text # demo为标签文本from bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser') # 解析的页面实例 实例一 .contents 1234567891011121314151617soup.head.contents # 结果呈现出列表形式&gt; [&lt;title&gt;This is a python demo page&lt;/title&gt;]soup.body.contents # 查看Body子节点的列表 &gt; ['\\n', &lt;p class=\"title\"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt;, '\\n', &lt;p class=\"course\"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses: &lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt; and &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;, '\\n']len(soup.body.contents)&gt; 5soup.body.contents[1] # 查看其下行节点的第二个&gt; &lt;p class=\"title\"&gt;&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;&lt;/p&gt; 标签树的下行遍历 遍历儿子节点（只遍历一层） 12for child in soup.body.children: print(child) 遍历子孙节点（所有节点） 12for child in soup.body.descendants: print(child) 5.2 标签树的上行遍历基本代码： 1234567891011soup = BeautifulSoup(demo,\"html.parser\")for parent in soup.a.parents: # 对a标签所有的先辈名字进行打印 if parent is None: print(parent) # 不存在父亲节，则不打印名称 else: print(parent.name) # 存在父亲节点，则打印出先辈节点名称 pbodyhtml[document] 5.3 标签树的平行遍历 属性 说明 .next_sibling 返回按照HTML文本顺序的下一个平行节点标签 .previous_sibling 返回按照HTML文本顺序的上一个平行节点标签 .next_siblings 迭代类型，返回按照HTML文本顺序的后续所有平行节点标签 .previous_siblings 迭代类型，返回按照HTML文本顺序的前续所有平行节点标签 注意：平行遍历发生在同一个父节点下的各节点间** 实例一 1234567891011121314soup.a.next_sibling &gt; ' and 'soup.a.next_sibling.next_sibling &gt; &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;soup.a.previous_sibling &gt; 'Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses:\\r\\n'soup.a.previous_sibling.previous_sibling # 此时输出为空 &gt;soup.a.parent.name &gt; 'p' 标签树的平行遍历基本代码 遍历后续节点 12for sibling in soup.a.next_siblings: print(sibling) 遍历前续节点 12for sibling in soup.a.previous_siblings: print(sibling) 6.HTML的格式化输出6.1 prettify()方法soup.prettify() # 显示换行符 print(soup.prettify()) # 格式化输出，标签树形式 6.2 bs4库的编码1234567soup = BeautifulSoup('&lt;p&gt;中文&lt;/p&gt;','html.parser')soup.p.string&gt; '中文'print(soup.prettify())&lt;p&gt; 中文&lt;/p&gt; 五、信息标记的三种形式 XML &lt;name 属性 Attribute(包含标签 Tag)&gt;...&lt;/name&gt; **JSON** 有类型的键值对 key:value 12345678 # 一键多值\"name\":[\"value1\",\"value2\",...] # 键值对的嵌套使用\"name\":&#123; \"key_1\": \"value1\", \"key_2\": \"value2\"&#125; YAML 123456789101112131415name : newName : value oldName : value # 表达并列关系name : - value1 - value2# |表达整块数据，#表示注释key : valuekey: #Comment- value1- value2key : subkey: subvalue 1.三种信息标记形式的比较 XML:Internet上的信息交互与传递。 JSON:移动应用云端和节点的信息通信，无注释。 YAML：各类系统的配置文件，有注释易读 2.信息提取的一般方法 方法一：完整解析信息的标记形式，再提取关键信息。 XML JSON YAML 需要标记解析器 例如：bs4库的标签树遍历 优点：信息解析准确 缺点：提取过程繁琐，速度慢。 方法二：无视标记形式，直接搜索关键信息。 搜索 对信息的文本查找函数即可 优点:提取过程简单，速度较快。 缺点：提取结果准确性与信息内容直接相关。 融合方法 融合方法：结合形式解析与搜索方法，提取关键信息。 XML JSON YMAL 搜索 需要标记解析器及文本查找函数 实例 提取HTML中的所有URL链接 思路： 搜索到所有标签 解析标签格式，提取href后的链接内容 3.基于bs4库的HTML内容查找方法前期工作 12345import requestsr = request.get('http://python123.io/ws/demo.html')demo = r.textfrom bs4 import BeautifulSoupsoup = BeautifulSoup(demo,'html.parser') &lt;&gt;.find_all(name,attrs,recursive,string,**kwargs) 返回一个列表类型，存储查找的结果。 name:对标签名称的检索字符串。 123456789101112131415161718192021222324soup.find_all('a') # 返回a标签的列表，可得其中两个属性&gt; [&lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt;, &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;]soup.find_all(['a','b']) # 同时查询'a','b'标签，以列表形式返回&gt;Out[65]: [&lt;b&gt;The demo python introduces several python courses.&lt;/b&gt;, &lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt;, &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;]In [67]: for tag in soup.find_all(True): # 查询所有的标签 ...: print(tag.name) ...: &gt; htmlheadtitlebodypbpaa attrs:对标签属性值的检索字符串，可标注属性检索。 1234567891011121314151617soup.find_all('p','course') # 返回p标签中所有的course属性Out[68]: [&lt;p class=\"course\"&gt;Python is a wonderful general-purpose programming language. You can learn Python from novice to professional by tracking the following courses: &lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt; and &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;.&lt;/p&gt;]soup.find_all(id='link1') # 返回id='link1'的全部标签信息Out[71]: [&lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt;]soup.find_all(id='link') Out[75]: []# 查询带有link(查询出所有的link，无论尾号为几），需要借助正则表达式import resoup.find_all(id=re.compile('link')) Out[79]: [&lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt;, &lt;a class=\"py2\" href=\"http://www.icourse163.org/course/BIT-1001870001\" id=\"link2\"&gt;Advanced Python&lt;/a&gt;] recursive:是否对子孙全部检索，默认True。 string:&lt;&gt;…&lt;/&gt;中字符串区域的检索字符串。 123456789# 只返回检索部分soup.find_all(string='Basic Python') Out[80]: ['Basic Python'] # 利用正则表达式，提取全部soup.find_all(string=re.compile('python')) # 提取全部带Python的过程Out[82]: ['This is a python demo page', 'The demo python introduces several python courses.'] &lt;tag&gt;(...)等价于 &lt;tag&gt;.find_all() soup(...)等价于soup.find_all(...) 4.扩展方法 方法 说明 &lt;&gt;.find() 搜索且只返回一个结果，字符串类型，同.find_all()参数 &lt;&gt;.find_parents() 在先辈节点中搜索，返回列表类型，同.find_all()参数 &lt;&gt;.find_parent() 在先辈节点中返回一个结果，字符串类型，同.find()参数 &lt;&gt;.find_next_siblings() 在后续平行节点中搜索，返回列表类型，同.find_all()参数 &lt;&gt;.find_next_sibling() 在后续平行节点中返回一个结果，字符串类型，同.find() &lt;&gt;.find_previous_siblings() 在前续平行节点中搜索，返回列表类型，同.find_all() &lt;&gt;.find_previous_sibling 在前续平行节点中返回一个结果，字符串类型，同.find() 六、正则表达式1.正则表达式语法1.1正则表达式由字符和操作符构成 操作符 说明 实例 . 表示任何单个字符 [] 字符集，对单个字符给出取值范围 [abc]表示a,b,c；[a-z]表示a到z单个字符 [^] 非字符集，对个单个字符给出排除范围 [^abc]表示非a或b或c的单个字符 * 前一个字符0次或无限次扩展 abc*表示ab、abc、abcc、abcc等 + 前一个字符1次或无限次扩展 abc+表示abc、abcc、abccc等 ？ 前一个字符0次或1次扩展 abc?表示ab、abc | 左右表达式任意一个 abc|def表示adc、def {m} 扩展前一个字符m次 ab{2}c表示abbc {m,n} 扩展前一个字符m至n次（含n） ab{1,2}c表示abc、abbc ^ 匹配字符串开头 ^abc表示abc且在一个字符串的开头 $ 匹配字符串结尾 abc$表示abc且在一个字符串的结尾 () 分组标记，内部只能使用|操作符 (abc)表示abc,(abc|def)表示abc、def \\d 数字，等价于[0-9] \\w 单词字符，等价于[A-Za-z0-9_] 举例 正则表达式 对应字符串 P(Y|YT|YTH|YTHO)?N ‘PN’,’PYN’,’PYTN’,’PYTHN’,’PYTHON’ PYTHON+ ‘PYTHON’,’PYTHONN’,’PYTHONNN’… PY[TH]ON ‘PYTON’,’PYHON’ PY[^TH]?ON ‘PYON’,’PYAON’,’PYBON’,… PY{:3}N ‘PN’,’PYYN’,’PYYYN’ 1.2经典正则表达式实例^[A-Za-z]+$ 由26个字母组成的字符串 ^[A-Za-z0-9]+$ 由26个字母和数字组成的字符串 ^-?\\d+$ 整数形式的字符串 - 表示负号 ^[0-9]*[1-9][0-9]*$ 正整数形式的字符串 [1-9]\\d{5} 中国境内邮政编码，6位 [\\u4e00- \\u9fa5] 匹配中文字符utf-8编码 \\d{3}-\\d{8}|\\d{4}-\\d{7} 国内电话号码，010-68913536 1.3匹配IP地址的正则表达式IP地址字符串形式的正则表达式（IP地址分4段，每段0-255） 粗略划分： \\d+.\\d+.\\d+.\\d+ \\d{1,3}.\\d{1,3}.\\d{1,3}.\\{1,3} 精确划分 0-99: [1-9]?\\d 100-199:1\\d{2} 200-249:2[0-4]\\d 250-255:25[0-5] 拼接：(([1-9]?\\d|1\\d{2}|2[0-4]\\d|25[0-5])\\.){3}([1-9]?\\d|1\\d{2}|2[0-4]\\d|25[0-5]) 2.Re库2.1 raw string类型（原生字符串类型）re库采用raw string类型表示正则表达式，表示为：r&#39;text&#39; 即：字符串原样输出，不用采用转移字符\\。 2.2 Re库主要功能函数 函数 说明 re.search() 在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象 re.match() 从一个字符串的开始位置起匹配正则表达式，返回match对象 re.findall() 搜索字符串，以列表类型返回全部能匹配的子串 re.split() 将一个字符串按照正则表达式匹配结果进行分割，返回列表类型 re.finditer() 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象 re.sub() 在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串 re.search(pattern,string,flags=0) 在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象。 pattern:正则表达式的字符串或原生字符串表示 string:待匹配字符串。 flags:正则表达式使用时的控制标记。 flags:正则表达式使用时的控制标记 常用标记 说明 re.I re.IGNORECASE 忽略正则表达式的大小写，[A-Z]能够匹配小写字符 re.M re.MULTILINE 正则表达式中的^操作符能够将给定字符串的每行当做匹配开始 re.S re.DOTALL 正则表达式中的.操作符能够匹配所有字符，默认匹配除换行外的所有字符 12345import rematch = re.search(r'[1-9]\\d&#123;5&#125;','BIT 100081')if match: print(match.group(0))&gt; 100081 re.match(pattern,string,flags=0) 1234import rematch = re.match(r'[1-9]\\d&#123;5&#125;','BIT 100081')match.group(0)&gt; AttributeError: 'NoneType' object has no attribute 'group' re.findall(pattern,string,flags=0) 123ls = re.findall(r'[1-9]\\d&#123;5&#125;','AAA100081 BBBB100084') ls&gt; ['100081', '100084'] re.split(pattern,string,maxsplit,flags=0) maxsplit:最大分割数目，达到数目，剩余部分作为最后一个元素输出。 12re.split(r'[1-9]\\d&#123;5&#125;','AAA100081 BBBB100084') # 将匹配的切割掉&gt; ['AAA', ' BBBB', ''] re.split(pattern,string,flags=0) 123456for m in re.finditer(r'[1-9]\\d&#123;5&#125;','AAA100081 BBBB100084'): # 迭代输出 if m: print(m.group(0))&gt; 100081100084 re.split(pattern,repl,string,count=0,flags=0) repl:替换匹配字符串的字符串 count:匹配的最大替换次数 2.3 Re库的另一种等价用法rst = re.search(r&#39;[1-9]\\d{5}&#39;,&#39;BIT 100081&#39;) 函数式用法：一次性操作 等价于： 123# 面向对象用法：编译后的多次操作pat = re.compile(r'[1-9]\\d&#123;5&#125;') rst = pat.search('BIT 100081') regex = re.compile(pattern,flags=0) 将正则表达式的字符串形式编译成正则表达式对象 pattern:正则表达式的字符串或原生字符串表示 flags:正则表达式使用时的控制标记 2.4 Match对象的属性 属性 说明 .string 待匹配的文本 .re 匹配时使用的pattern对象（正则表达式） .pos 正则表达式搜索文本的开始位置 .endpos 正则表达式搜索文本的结束位置 2.5 Match对象的方法 方法 说明 .group(0) 获取匹配后的字符串 .start() 匹配字符串在原始字符串的开始位置 .end() 匹配字符串在原始字符串的结束位置 .span() 返回(.start(),.end()) 2.6 Re库的贪婪匹配和最小匹配实例: 123match = re.search(r'PY.*N','PYANBNCNDN')match.group(0)Out[101]: 'PYANBNCNDN' Re库默认采用贪婪匹配，即输出匹配最长的子串。 最小匹配 123match = re.search(r'PY.*?N','PYANBNCNDN')match.group(0)Out[102]: 'PYAN' 最小匹配操作符 操作符 说明 *? 前一个字符0次或无限次扩展，最小匹配 +? 前一个字符1次或无限次扩展，最小匹配 ?? 前一个字符0次或1次扩展，最小匹配 {m,n}? 扩展前一个字符m至n次（含n），最小匹配 未完待续….","categories":[{"name":"Python","slug":"Python","permalink":"https://www.liizhi.cn/categories/Python/"},{"name":"爬虫","slug":"Python/爬虫","permalink":"https://www.liizhi.cn/categories/Python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"https://www.liizhi.cn/tags/%E7%88%AC%E8%99%AB/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://www.liizhi.cn/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"Request","slug":"Request","permalink":"https://www.liizhi.cn/tags/Request/"},{"name":"Beautifulsoup","slug":"Beautifulsoup","permalink":"https://www.liizhi.cn/tags/Beautifulsoup/"}]},{"title":"JDBC基础使用","slug":"JDBC基础使用","date":"2020-03-17T17:42:42.000Z","updated":"2020-03-17T19:44:13.725Z","comments":true,"path":"2020/03/18/JDBC基础使用/","link":"","permalink":"https://www.liizhi.cn/2020/03/18/JDBC%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","excerpt":"JDBC:Java DataBase Connectivity,即为Java数据库连接。 JDBC是Java语言中用来规范客户端程序如何来访问数据库的应用程序接口，提供了诸如查询和更新数据库中数据的方法。即：定义的一套操作所有关系型数据库的规则，是为接口。各个数据库厂商去实现这套接口，提供数据库驱动jar包。我们可以使用这套接(JDBC)编程，真正执行的代码是驱动jar包中的实现类。","text":"JDBC:Java DataBase Connectivity,即为Java数据库连接。 JDBC是Java语言中用来规范客户端程序如何来访问数据库的应用程序接口，提供了诸如查询和更新数据库中数据的方法。即：定义的一套操作所有关系型数据库的规则，是为接口。各个数据库厂商去实现这套接口，提供数据库驱动jar包。我们可以使用这套接(JDBC)编程，真正执行的代码是驱动jar包中的实现类。 JDBC简单使用快速入门 步骤： 导入驱动jar包 mysql-connector-java-5.1.37-bin.jar 1.复制mysql-connector-java-5.1.37-bin.jar到项目的libs目录下 2.右键–&gt;Add As Library 注册驱动 获取数据库连接对象 Connection 定义sql 获取执行sql语句的对象 Statement 执行sql，接受返回结果 处理结果 释放资源 12345678910111213141516171819202122232425262728import java.sql.Connection;import java.sql.DriverManager;import java.sql.Statement;public class JDBCDemo01 &#123; /** * 更新一条数据库数据 * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; //1.导入驱动jar包（类似于Python中的第三方库 //2.注册驱动 Class.forName(\"com.mysql.jdbc.Driver\");// //3.获取数据库连接对象 jdbc:mysql://localhost:3306/databases 本机 Connection conn = DriverManager.getConnection(\"jdbc:mysql://url:port/Database\", \"username\", \"password\"); //4.定义sql语句 String sql = \"update account set balance = 500 where id = 1\"; //5.获取执行sql的对象Statement Statement stmt = conn.createStatement(); //6.执行sql int count = stmt.executeUpdate(sql); //7.处理结果 System.out.println(count); stmt.close(); conn.close(); &#125;&#125; 因为，在数据库连接、SQL语句的执行等等过程中，可能会发生异常，报错等。但是，数据库的资源要释放，故采用异常处理的方式，关闭数据库连接。 处理异常的方式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;import java.sql.Statement;/** * 1.采用异常的方式通过JDBC连接数据库 * 2.插入一条语句 */public class JDBCDemo02 &#123; public static void main(String[] args) &#123; // 为了使Connection方法可以接受到值，故将参数提升到成员变量的位置上 Statement stmt = null; Connection conn = null; // 异常捕获的方式处理异常 try &#123; //1.注册驱动 Class.forName(\"com.mysql.jdbc.Driver\"); //2.定义SQL语句 String sql = \"insert into account values(null,'Lisa',2000)\"; //3.获取连接对象 conn = DriverManager.getConnection(\"jdbc:mysql://url:port/db3\", \"username\", \"password\"); //4.获取执行sql对象 stmt = conn.createStatement(); //5.执行sql int count = stmt.executeUpdate(sql); if (count &gt; 0) &#123; System.out.println(\"修改成功\"); &#125; else &#123; System.out.println(\"修改失败\"); &#125; &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; finally &#123; if (stmt != null) &#123; try &#123; stmt.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 详解 DriverManager：驱动管理对象 用于注册驱动，jar包导入。 12345678通过查看源码发现：在com.mysql.jdbc.Driver类中存在静态代码块 static &#123; try &#123; java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(\"Can't register driver!\"); &#125; &#125; 原因：文件的读取，只需要读取一次，即可拿到这些值。故使用静态代码块完成。 static Connection getConnection(String url, String user, String password) Connection：数据库连接对象 功能： 1. 获取执行sql的对象 * `Statement createStatement()` * `PreparedStatement prepareStatement(String sql)` 2. 事务管理： * 开启事务：setAutoCommit(boolean autoCommit) ：调用该方法设置参数为false，即开启事务 * 提交事务：commit() * 回滚事务：rollback() 3. `Statement`：执行sql的对象 **注意**：`createStatement`方法会造成SQL注入的问题，后期采用`PreparedStatement`来执行SQL对象，并采用预编译的方式，采用参数`?`作为占位符,且效率更高。 4. `ResultSet`：结果集对象,封装查询结果(next,类似指针移动取值方法) * boolean next(): 游标向下移动一行，判断当前行是否是最后一行末尾(是否有数据)，如果是，则返回false，如果不是则返回true. * getXxx(参数):获取数据. - 其中Int代表列的编号，参数**从1开始**。 - String代表列的名称（参数）。 JDBC操作数据库的一般SQL语法 更新操作 String sql = &quot;update account set balance = 500 where id = 1&quot;; 插入操作 String sql = &quot;insert into account values(null,&#39;Lisa&#39;,2000)&quot;; 删除操作 String sql = &quot;delete from account where id = 3&quot;; 创建操作 1234String sql = \"create table student (id int primary key not null,name varchar(20))\";stmt = conn.createStatement();int count = stmt.executeUpdate(sql);//处理结果，创建表返回的为0System.out.println(count); 查询操作 123456789String sql = \"select * from account\";stmt = conn.createStatement();resultSet = stmt.executeQuery(sql);while (resultSet.next()) &#123; //resultSet指针下移一行，并判断当前行内容是否为空，内容不为空，进入循环体 int id = resultSet.getInt(1);// 取第一列的元素 String name = resultSet.getString(\"NAME\"); int balance = resultSet.getInt(3); System.out.println(id + \"---\" + name + \"---\" + balance);&#125; 参考文献 [1] Java数据库连接 [2] Itcast视频资料","categories":[{"name":"Java","slug":"Java","permalink":"https://www.liizhi.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.liizhi.cn/tags/Java/"},{"name":"JDBC","slug":"JDBC","permalink":"https://www.liizhi.cn/tags/JDBC/"},{"name":"MySQL","slug":"MySQL","permalink":"https://www.liizhi.cn/tags/MySQL/"}]},{"title":"机器学习:决策树入门之泰坦尼克号案例","slug":"机器学习-决策树入门之泰坦尼克号案例","date":"2020-02-08T20:01:22.000Z","updated":"2020-03-14T14:13:00.553Z","comments":true,"path":"2020/02/09/机器学习-决策树入门之泰坦尼克号案例/","link":"","permalink":"https://www.liizhi.cn/2020/02/09/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%86%B3%E7%AD%96%E6%A0%91%E5%85%A5%E9%97%A8%E4%B9%8B%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E6%A1%88%E4%BE%8B/","excerpt":"本文用于记录机器学习中的一次入门练习，即：利用决策树进行简单的二分类。同时，结合Kaggle上的经典案例Titanic，来测试实际效果。 一、数据集采用Kaggle中的Titanic的数据集。数据包含分为： 训练集: training set (train.csv) 测试集: test set (test.csv) 提交标准: gender_submission.csv 由于Kaggle涉及到科学上网的操作，所以原始数据集已经下载好放在Gighub上了。 二、数据处理首先导入训练集，查看数据的情况： 123456789from sklearn.tree import DecisionTreeClassifier # 导入模型决策树分类器from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV # 导入的模型作用分别为交叉验证、训练集与数据集的划分，网格搜索import pandas as pdimport numpy as npimport matplotlib.pyplot as pltdata = pd.read_csv('/Users/liz/code/jupyter-notebook/sklearn/1- DecisionTree/Titanic_train.csv') # 导入数据集data.head() # 显示数据集的前五行[out]:","text":"本文用于记录机器学习中的一次入门练习，即：利用决策树进行简单的二分类。同时，结合Kaggle上的经典案例Titanic，来测试实际效果。 一、数据集采用Kaggle中的Titanic的数据集。数据包含分为： 训练集: training set (train.csv) 测试集: test set (test.csv) 提交标准: gender_submission.csv 由于Kaggle涉及到科学上网的操作，所以原始数据集已经下载好放在Gighub上了。 二、数据处理首先导入训练集，查看数据的情况： 123456789from sklearn.tree import DecisionTreeClassifier # 导入模型决策树分类器from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV # 导入的模型作用分别为交叉验证、训练集与数据集的划分，网格搜索import pandas as pdimport numpy as npimport matplotlib.pyplot as pltdata = pd.read_csv('/Users/liz/code/jupyter-notebook/sklearn/1- DecisionTree/Titanic_train.csv') # 导入数据集data.head() # 显示数据集的前五行[out]: PassengerId Survived Pclass Name Sex Age SlibSp Parch Ticek Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th… female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 通过以上的数据所展示的情况，我们所要做的是将Survived作为标签，其余的列作为特征。目标：以所知的特征来预测标签。这份数据集的实际意义是:通过已知数据对乘客的生还情况做一次预测。 12345678910111213141516171819data.info() # 查看整个训练集的情况out: &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): PassengerId 891 non-null int64 Survived 891 non-null int64 Pclass 891 non-null int64 Name 891 non-null object Sex 891 non-null object Age 714 non-null float64 SibSp 891 non-null int64 Parch 891 non-null int64 Ticket 891 non-null object Fare 891 non-null float64 Cabin 204 non-null object Embarked 889 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB 数据分析 通过以上的数据展示，共有891条数据，其中具有缺失值的特征有：Age、Cabin、Embarked；非数值型的特征有：Name,Sex,Ticket,Cabin,Embarked。 当我们采用现有的特征对乘客进行生还情况预测时，一些处理较为麻烦且不太重要的特征对可不采用。例如：这里的Name、Ticket可以不采用，因为在实际情况中乘客的名字以及所购的票对于乘客的生还情况作用不大。另外一点原因是这两者皆为非数值型数据，处理成数值形式较为复杂（在计算机中所接受的数据最终都要以数字的形式进行呈现）。 由于Cabin缺失值较多，这里采用删除的方式，理由同上。 虽然性别也为字符型数据，当在实际中性别对于逃生的可能性具有一定的影响，故对其保留。 将缺失值进行填补；将非数值型数据转化为数值型数据。 12345678910111213141516171819202122232425262728293031323334353637383940# 删除Name、Ticket、Cabin特征列data.drop(['Name','Cabin','Ticket'],inplace=True,axis=1)# 缺失值的填补# 对于Age的缺失值填补的一种策略为：以年龄的平均值作为填补data.loc[:,'Age'] = data['Age'].fillna(int(data['Age'].mean()))# Embarked由于只有两条数据具有缺失值，这里采用的方式是删除这两条缺失的数据（缺失两条数据对模型的训练好坏影响不大）data = data.dropna()data = data.reset_index(drop = True) # 删除过后，用于重置索引# 将非数值型数据转化为数值型数据# 性别只有两类，故可用0\\1来表示男女data['Sex'] = (data['Sex'] == 'male').astype(int) # 0表示女，1表示男tags = data['Embarked'].unique().tolist() # tags: ['S', 'C', 'Q']# Embarked只有三类分别以S,C,Q的索引代表他们,0~9均可采用此种方法data.iloc[:,data.columns == 'Embarked'] = data['Embarked'].apply(lambda x : tags.index(x))# 查看数据data.info() # 查看数据信息out:&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 889 entries, 0 to 888Data columns (total 9 columns):PassengerId 889 non-null int64Survived 889 non-null int64Pclass 889 non-null int64Sex 889 non-null int64Age 889 non-null float64SibSp 889 non-null int64Parch 889 non-null int64Fare 889 non-null float64Embarked 889 non-null int64dtypes: float64(2), int64(7)memory usage: 62.6 KB# 将特征与标签进行分离x = data.iloc[:,data.columns != 'Survived'] # 取出Survived以为的列作为特征xy = data.iloc[:,data.columns == 'Survived'] # 取出Survived列作为特征y 模型训练思路：采用交叉验证来评估我们的模型；同时采用网格搜索来查找决策树中常见的最佳参数。 12345678910111213141516171819202122232425# 网格搜索：能够帮助我们同时调整多个参数的技术，本质是枚举技术。# paramerters：用于确定的参数。parameters = &#123;'splitter':('best','random') ,'criterion':('gini','entropy') ,'max_depth':[*range(1,10)] ,'min_samples_leaf':[*range(1,50,5)] ,'min_impurity_decrease':[*np.linspace(0,0.5,20)] &#125;# 网格搜索实例代码，所需要确定的参数越多，耗时越长clf = DecisionTreeClassifier(random_state=30)GS = GridSearchCV(clf,parameters,cv=10) # cv=10,做10次交叉验证GS = GS.fit(x_train,y_train)# 最佳参数GS.best_params_out: &#123;'criterion': 'gini', 'max_depth': 3, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'splitter': 'best'&#125; # 最佳得分GS.best_score_ 确定了设置的参数的最佳值，开始训练模型： 12345678# 训练模型，将以上设置参数的最佳值填入模型的实例化中clf_model = DecisionTreeClassifier(criterion='gini' ,max_depth=3 ,min_samples_leaf=1 ,min_impurity_decrease=0 ,splitter='best' )clf_model = clf_model.fit(x,y) 导出模型： 123# 导出模型from sklearn.externals import joblibjoblib.dump(clf_model,'/Users/liz/Code/jupyter-notebook/sklearn/1- DecisionTree/clf_model.m') 测试集的处理： 1234567891011121314151617181920212223242526272829# 导入测试集data_test = pd.read_csv('/Users/liz/code/jupyter-notebook/sklearn/1- DecisionTree/Titanic_test.csv')data_test.info()out: &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 418 entries, 0 to 417 Data columns (total 11 columns): PassengerId 418 non-null int64 Pclass 418 non-null int64 Name 418 non-null object Sex 418 non-null object Age 332 non-null float64 SibSp 418 non-null int64 Parch 418 non-null int64 Ticket 418 non-null object Fare 417 non-null float64 Cabin 91 non-null object Embarked 418 non-null object dtypes: float64(2), int64(4), object(5) memory usage: 36.0+ KB# 测试集处理的方法同训练集，同时测试集要与训练集保持同样的特征# 由于最后，我们需要将处理结果上传到Kaggle上，所以不能够将数据条目减少，即：需要上传418条测试数据；故这里Fare缺失的一条数目同样采用平均值来填补data_test.drop(['Name','Ticket','Cabin'],inplace=True,axis=1)data_test['Age'] = data_test['Age'].fillna(int(data_test['Age'].mean()))data_test['Fare'] = data_test['Fare'].fillna(int(data_test['Fare'].mean()))data_test.loc[:,'Sex'] = (data_test['Sex'] == 'male').astype(int)tags = data_test['Embarked'].unique().tolist()data_test['Embarked'] = data_test['Embarked'].apply(lambda x : tags.index(x)) 此时测试集数据预处理完毕，导出模型并对数据进行测试： 123456789101112# 导出模型且测试数据集model = joblib.load('/Users/liz/Code/jupyter-notebook/sklearn/1- DecisionTree/clf_model.m')Survived = model.predict(data_test) # 测试结果# 生成数据Survived = pd.DataFrame(&#123;'Survived':Survived&#125;) # 将结果转换为字典形式并后续作为csv形式导出PassengerId = data_test.iloc[:,data_test.columns == 'PassengerId'] # 切片，分割出PassengerIdgender_submission = pd.concat([PassengerId,Survived],axis=1)# 将Survived与PassengerId拼接，一一对应#导出数据#导出数据gender_submission.index = np.arange(1, len(gender_submission)+1) # 索引从1开始gender_submission.to_csv('/Users/liz/Code/jupyter-notebook/sklearn/1- DecisionTree/gender_submission.csv',index=False) # index=False，导出时不显示索引 导出文件: PassengerId Survived 0 892 0 1 893 1 2 894 0 3 895 0 4 896 1 ... ... ... 413 1305 0 414 1306 1 415 1307 0 416 1308 0 417 1309 0 418 rows × 2 columns 将结果提交到Kaggle上，最终得分： 最终得分0.77990，分数不高，最高有得满分的，此篇只是作为机器学习及Kaggle的一个入门。 最终的源代码及Kaggle的数据集都会上传到我的Github仓库中，其中也包括一些网络上搬运的相关笔记也都会上传到Github上,此仓库会持续更新… 附 下载源码","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"https://www.liizhi.cn/categories/Machine-Learning/"}],"tags":[{"name":"DecisionTree","slug":"DecisionTree","permalink":"https://www.liizhi.cn/tags/DecisionTree/"},{"name":"Kaggle","slug":"Kaggle","permalink":"https://www.liizhi.cn/tags/Kaggle/"}]},{"title":"云端MySQL安装及相关配置","slug":"云端MySQL安装及相关配置","date":"2020-01-22T13:27:59.000Z","updated":"2020-03-14T14:12:12.893Z","comments":true,"path":"2020/01/22/云端MySQL安装及相关配置/","link":"","permalink":"https://www.liizhi.cn/2020/01/22/%E4%BA%91%E7%AB%AFMySQL%E5%AE%89%E8%A3%85%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE/","excerpt":"由于自己的阿里云账号申请不足6个月，能够享受新用户云服务器ECS89元一年的优惠政策，所以就购买了一台云服务器，作为日常学习的使用。本文用来记录此次装载云服务器所遇到的一些问题及MySQL的安装过程。 一、云服务器的选配及配置此次我选购的服务器网址:http://aliyun.langsan.com/?bd_vid=8575091722087683835。下图为此次所购的云服务器配置:","text":"由于自己的阿里云账号申请不足6个月，能够享受新用户云服务器ECS89元一年的优惠政策，所以就购买了一台云服务器，作为日常学习的使用。本文用来记录此次装载云服务器所遇到的一些问题及MySQL的安装过程。 一、云服务器的选配及配置此次我选购的服务器网址:http://aliyun.langsan.com/?bd_vid=8575091722087683835。下图为此次所购的云服务器配置: 后续步骤为：提货券的兑换；地域站点的选取以及系统的选配。这里我选取的为上海的站点（大陆境内站点随便选没什么差别），系统选装的为Centos7(具体到7.x没什么区别)。然后就是阿里云那边的自动配置了。购买及配置较为简单，全部为阿里云的傻瓜一站式操作。 二、安全组的设置第一次服务器的使用，需要进行安全组的设置。进入到自己的控制台-实例与镜像-实例。这个时候就能够看到自己的服务器。勾选此台服务器： 依次设置实例ID、重置实例密码； 在更多选项中选择密码/密匙。重置远程连接的密码。 注:实例密码为操作系统的密码，即为root用户名密码。在实例创建时可选设定，如果没有设定或者遗忘可在阿里云的个人控制台上进行密码重置操作；远程链接密码是通过个人后台控制面板，通过内网形式直接链接到操作系统上，这种链接方式可以绕过安全组拦截，一般用于安全组将远程端口拦截时选择此种方法。 网络与安全组。将此实例加入到安全组里。 设置安全组规则 在安全组规则中，采用快速创建规则。规则方向：入方向/出方向，均可采用，用于控制服务器访入与访出。授权策略：允许/禁止（不解释）。常用端口（TCP）:控制端口的访入与访出（根据自己的习惯与用处）。授权对象:默认为0.0.0.0/0。至此服务器基本配置到此结束。回到控制台实例中，点击远程连接。区域即为所选区域（一般默认不变）；端口默认为22；用户名默认为root；密码是之前设置的实例密码。 三、本机ssh连接服务器免密设置上一部分中，我们在阿里云的网页实例中，远程连接到我们的服务器。但是，每当我们需要用到服务器时，便要通过阿里云账号登录再来连接就显得比较麻烦。这里，通过ssh的命令在自己电脑终端来远程连接自己的服务器。终端命令：ssh root@ip root:远程连接的用户名；一般默认不变即为root。 ip:自己服务器公网ip。回车后，输入自己的root用户实例密码即可连接。注：Linux、Mac系统终端自带ssh命令；Windows系统不自带ssh命令，需要借助putty或Xshell客户端软件使用。但是，每次我们在自己的电脑连接到服务器都需要通过ip地址，再由密码登录也比较麻烦。所以这里再介绍本机免密码登录服务器的方式。思路：将自己的公有密匙添加到服务器端。 1.在本地生成一对公匙-密匙ssh-keygen -t rsa采用默认目录，不设置密码，一路回车即可。 最终会在~/.ssh目录下生成id_rsa(密匙)；id_rsa.pub(公匙)。 2.将公匙部署至服务器上在本地命令执行：方式一:scp ~/.ssh/id_rsa.pub root@公网IP地址:～/.ssh/authorized_keys方式二：ssh-copy-id ~/.ssh/id_rsa.pub root@公网IP地址以上两种方式即将本地公匙内容复制到远程服务器～/.ssh/authorized_keys的文件中。 至此，再次登录服务器只需一句ssh终端命令即可，不需要再输入密码。到这里还不是最简洁的一种登录方式，因为我们还需要输入root用户账号，ip地址。所以后续还有更简洁的方式：本地需要保存ssh登录主机的相关信息，在本地主机用户根目录下的.ssh文件内创建config文件，用于保存ssh登陆主机的相关信息vim config（如果没有vim可以手动到此目下创建config文件）编辑内容： 12345Host name #AAAAA为服务器主机名HostName 39.97.170.231 #写服务器ip地址User root #root为登陆用户名Port 22 #主机端口，默认是22IdentityFile &#x2F;Users&#x2F;.ssh&#x2F;id_rsa #自己生成的私钥的文件路径 注意：Host name是之前服务器设置中设置的实例id/名称实例如下： 3.在服务器设置自动检验的信息打开/etc/ssh/sshd_config文件vim /etc/ssh/sshd_config找到 12PubkeyAuthentication yes AuthorizedKeysFile .ssh&#x2F;authorized_keys 取消注释。至此，以后在自己本机上只需要采用:ssh liz_es即可登录。 四、 MySQL服务器的安装及相关配置MySQ安装这一部分记录云服务器端安装MySQL及相关配置 下载并安装MySQL官方的Yum Repository[root@localhost ~]# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm使用上面的命令直接安装Yum Repository[root@localhost ~]# yum -y install mysql57-community-release-el7-10.noarch.rpm 安装MySQL服务器root@localhost ~]# yum -y install mysql-community-server[root@localhost ~]# yum -y remove mysql57-community-release-el7-10.noarch MySQL数据库设置MySQL的启动[root@localhost ~]# systemctl start mysqld.serviceMySQL的关闭systemctl stop mysqld.service查看MySQL运行状态[root@localhost ~]# systemctl status mysqld.service查找root初始密码[root@localhost ~]# grep &quot;password&quot; /var/log/mysqld.log登录MySQLmysql -uroot -p此时需要修改初始密码才能对数据库进行后续操作。又由于数据库默认的密码强度所设置的密码较为复杂，所以需要事先修改密码强度规则。否则在修改密码的过程容易出现以下错误：ERROR 1819 (HY000): Your password does not satisfy the current policy requiremen下面列出常用的关于密码设置方面的MySQL操作命令。查看MySQL密码相关的全局参数：mysql&gt; select @@validate_password_policy;mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;; 参数解释validate_password_dictionary_file插件用于验证密码强度的字典文件路径。validate_password_length 密码最小长度，参数默认为8，它有最小值的限制，最小值为：validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)validate_password_mixed_case_count密码至少要包含的小写字母个数和大写字母个数。 validate_password_number_count密码至少要包含的数字个数。validate_password_policy密码强度检查等级，0/LOW、1/MEDIUM、2/STRONG。validate_password_special_char_count 密码至少要包含的特殊字符数。 修改mysql参数配置1234567891011121314151617mysql&gt; set global validate_password_policy&#x3D;0; Query OK, 0 rows affected (0.05 sec) mysql&gt; set global validate_password_mixed_case_count&#x3D;0; Query OK, 0 rows affected (0.00 sec) mysql&gt; set global validate_password_number_count&#x3D;5; Query OK, 0 rows affected (0.00 sec) mysql&gt; set global validate_password_special_char_count&#x3D;0; Query OK, 0 rows affected (0.00 sec) mysql&gt; set global validate_password_length&#x3D;2; Query OK, 0 rows affected (0.00 sec) mysql&gt; SHOW VARIABLES LIKE &#39;validate_password%&#39;; mysql&gt; FLUSH PRIVILEGES 可能最后两句在执行时，会报错。这是因为还没对初始密码进行修改。在修改完密码以后FLUSH PRIVILEGES，保证密码强度规则的更新。 MySQL密码的修改mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;new password&#39;; MySQL用户的创建及权限设置在MySQL中其实有一个内置且名为mysql的数据库，这个数据库中存储的是MySQL的一些数据，比如用户、权限信息、存储过程等。通过以下命令可查看当前数据库存在哪些用户；SELECT User, Host FROM mysql.user;可看见如下类似信息： 12345678+---------------+-----------+| User | Host |+---------------+-----------+| re_mysql | % || mysql.session | localhost || mysql.sys | localhost || root | localhost |+---------------+-----------+ Host代表用户所能连接的数据库主机 % 代表任何主机localhost 代表只能在本机上使用的用户 创建用户mysql&gt;CREATE USER &#39;user_name&#39;@&#39;host&#39; IDENTIFIED BY &#39;password&#39;;user_name:需要创建的用户名称。host:表示要这个新创建的用户允许从哪台机登陆，如果只允许从本机登陆，则填‘localhost’ ；如果指定某台主机登录，则填’ip’;如果允许从任意远程登陆，则填 ‘%’；password:新创建用户的数据库登录密码，需符合密码强度规则。 授权用户GRANT ALL PRIVILEGES ON *.* TO &#39;user_name&#39;@&#39;%&#39; IDENTIFIED BY &#39;password&#39; WITH GRANT OPTION;PRIVILEGES:表示要授予什么权限。例如可以有 select ,insert ,delete,update等,如果要授予全部权力,则填ALL。 *.*:表示用户的权限能用在哪个库的哪个表中，如果想要用户的权限很作用于所有的数据库所有的表，则填*.*，*是一个通配符，表示全部。user_name:所要授权的用户。&#39;%&#39;:表面所有远程都可在此用户登录MySQL服务器，具体使用同节。WITH GRANT OPTION:用以上命令授权的用户不能给其他用户授权，如果想这个用户能够给其他用户授权，就要在后面加上WITH GRANT OPTION。 删除用户DROP USER ‘user_name’@‘localhost/ip/*’ 立即生效flush privileges 修改mysql库里边的user表，限制root用户只能从哪个ip登录update mysql.user set host=&#39;localhost&#39; where user=&#39;root&#39;; MySQL的远程连接云服务器端部署好了MySQL。那么可以在本机中连接云服务器端的MySQL数据库。这里，我借助的是Navicat for MySQL。创建连接： 连接名：随便写。主机：云服务器的公有IP。端口：默认端口3306。用户名:即在上一节中创建的新用户，并且是能够远程连接的用户。编辑密码：MySQL这一用户的密码。点击测试连接。 成功！以后便可以在本机连接到服务器端的MySQL进行使用。 注意当在虚拟机(Ubuntu16.04)中的MySQL采取同样的操作时，可能连接失败。在百度了一番博文以后，所采用的办法是在虚拟机的终端： cd /etc/mysql 进入到my.cnf文件所在的目录下，sudo cp my.cnf my.cnf.bak，备份文件 打开配置，找到bind-address= 127.0.0.1这一行，注释掉。 重启数据库，使用Navicat进行连接。 附 Markdown常用命令：https://www.runoob.com/markdown/md-tutorial.html vim常用命令：https://www.runoob.com/linux/linux-vim.html 菜鸟：https://www.runoob.com/ 免费的图床-路过图床：https://imgchr.com/ hexo高阶教程：想让你的博客被更多的人在搜索引擎中搜到吗? Hexo 教程：Hexo 博客部署到腾讯云教程 hexo史上最全搭建教程 git 清除缓存 git rm -r –cached .git add .git commit -m ‘update .gitignore’ 参考文献 [1] centos7下安装mysql（完整配置）:https://blog.csdn.net/baidu_32872293/article/details/80557668[2] mysql 密码强度规则设置:https://blog.csdn.net/u014236541/article/details/78244601[3] MYSQL的创建用户，授权用户，删除用户，查看用户:https://blog.csdn.net/u014453898/article/details/55064312[4] mysql查看所有用户:https://blog.csdn.net/qq_37996815/article/details/78934536[5] Ubuntu 16.04 安装使用MySQL:https://blog.csdn.net/vXueYing/article/details/52330180[6] 使用navicat 连接虚拟机上的MySQL数据库:https://www.jianshu.com/p/8fa82acb16e9[7] SSH连接服务器 本地记住用户名及密码:https://blog.csdn.net/persist_xyz/article/details/90231433","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.liizhi.cn/categories/Linux/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.liizhi.cn/tags/MySQL/"},{"name":"Linux","slug":"Linux","permalink":"https://www.liizhi.cn/tags/Linux/"}]},{"title":"Linux-Ubuntu的安装与相关设置","slug":"Linux-Ubuntu的安装与相关设置","date":"2020-01-17T10:12:49.000Z","updated":"2020-03-15T18:16:42.508Z","comments":true,"path":"2020/01/17/Linux-Ubuntu的安装与相关设置/","link":"","permalink":"https://www.liizhi.cn/2020/01/17/Linux-Ubuntu%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E7%9B%B8%E5%85%B3%E8%AE%BE%E7%BD%AE/","excerpt":"近日换了电脑，想装一个Linux系统，但也不想在本机上装双系统，就选择了装起虚拟机。此次选择了安装Ubuntu 16.04.6版本，文章最后会附上常用16.04和18.04ubuntu镜像源下载的网址。本文，用来记录此次虚拟机的装载过程、后续配置。 一、VMWare Fusion的下载VMware Fusion是VMware为Macintosh计算机开发的虚拟机管理程序。用来管理虚拟机环境。此次选择了11.5.1的版本-下载地址。序列号查询百度即可。 二、Ubuntu的安装打开VMWare Fusion，点击创建新环境。选择创建自定义虚拟机安装。这里没有选择上方的镜像安装，是因为我在第一次用这种方法安装完以后，尝试了各种方法却不能安装VMware tools。","text":"近日换了电脑，想装一个Linux系统，但也不想在本机上装双系统，就选择了装起虚拟机。此次选择了安装Ubuntu 16.04.6版本，文章最后会附上常用16.04和18.04ubuntu镜像源下载的网址。本文，用来记录此次虚拟机的装载过程、后续配置。 一、VMWare Fusion的下载VMware Fusion是VMware为Macintosh计算机开发的虚拟机管理程序。用来管理虚拟机环境。此次选择了11.5.1的版本-下载地址。序列号查询百度即可。 二、Ubuntu的安装打开VMWare Fusion，点击创建新环境。选择创建自定义虚拟机安装。这里没有选择上方的镜像安装，是因为我在第一次用这种方法安装完以后，尝试了各种方法却不能安装VMware tools。 继续下一步选择所要安装的操作系系统，这里为Ubuntu 64位。选择UEFI安装模式。后续的步骤中就一路下一步。安装过程中，如果VMware没有检测到我们所需要安装的镜像源，那么需要我们将镜像源手动添加到配置中。若卡在这里不动，便需要我们手动添加镜像源。) 后续就是VMware的全自动配置安装了。注意：后续语言环境的安装，请选择默认的English,不要改成简体中文模式。因为，当我们熟练了Linux的终端命令以后，我们就不再进行图形化界面的操作，而是转变为字符界面的操作。如果，开始默认的是中文简体，那么在字符界面中，中文会出现菱形乱码，无法识别。从这里的后续安装可以参考百度百科。在VMware的一系列自动安装配置以后。若出现了:将上述添加的磁盘勾选取消点击虚拟机重启即可！登录，进入图形化界面！ 三、Ubuntu的镜像源设置这里介绍两种方式。第一种方式：点击右上方的设置按钮，进入System settings…在系统栏中选择Software&amp;Updates,将Downloads中的镜像源Others选成Chinese，然后点击右方的选取Select Best Server，等待系统测试选取最佳的节点，再依据后续步骤更新即可。第二种方式：参考清华大学开源软件镜像源。按要求和版本号将配置文件改成清华大学的镜像源即可。 四、VMWare Tools的安装此时，Ubuntu已经安装好了。但是，如果要想做到本机和虚拟机能够文件共享，那么还需要下载VMWare Tools。点击：由于我的已经安装过了，所以这里显示为重新安装，后续按照下载。点击安装。 将安装好的压缩包，VMWaretools-XXX(版本号).tar.gz。移动到桌面。 打开Ubuntu下的终端命令窗口。 12345cd Desktop # 进入桌面ls # 查看此压缩包是否在桌面下tar -xzvf VMWaretools-XXX(版本号).tar.gz # 解压文件cd VMware-tools-distrib.&#x2F;vmware-install.pl # 执行vmware-install.pl 进行安装 依次执行以上命令后，按照提示在终端中输入yes和回车即可。 五、共享文件夹的设置上述步骤中中，安装了VMWare tools，后续就需要设置我们可以共享的文件夹。进入Ubuntu的硬件设置中：进入共享文件夹。添加系统文件夹，重启虚拟机。VMWare tools可以使本机和虚拟机之间共享文件；同时可以自动调节虚拟机的分辨率，使得全屏放映使用。 六、图形界面和字符界面的转换首先打开虚拟机中的终端，sudo su进入root模式。 修改grub文件 sudo vi /etc/default/grub 修改grub文件的三处： 将GRUB_CMDLINE_LINUX_DEFAULT=”quiet splash”进行注释，即最前方加#。 GRUB_CMDLINE_LINUX=”text”,添加为text，文本。 GRUB_TERMINAL=console，取消注释。 最终的修改结果如下图：保存退出。 sudo update-grub更新grub文件。 执行sudo systemctl set-default multi-user.target 即将开机默认方式改为字符形界面。 重新启动虚拟机。注意:不要使用reboot总结:以后两种模式的转化只需要两句终端命令即可。 图形转字符界面：sudo systemctl set-default multi-user.target 字符转图形界面：sudo systemctl set-default graphical.target 最后重启虚拟机，即可！ 附： Ubuntu安装的镜像网站： 14.04版本：http://mirrors.aliyun.com/ubuntu-releases/14.04/ 16.04版本：http://mirrors.aliyun.com/ubuntu-releases/16.04/ 18.04版本：http://mirrors.aliyun.com/ubuntu-releases/18.04/ 清华大学镜像源：https://mirrors.tuna.tsinghua.edu.cn/ VMWare FUsion安装地址：https://my.vmware.com/cn/web/vmware/info/slug/desktop_end_user_computing/vmware_fusion/11_0 参考文献 [1] mac上用VMWare虚拟机装Ubuntu–及Ubuntu安装Vmware Tools[2] 如何安装ubuntu系统[3] VMware Tools安装[4] Ubuntu16.04 图形界面与字符界面切换","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.liizhi.cn/categories/Linux/"}],"tags":[{"name":"VMware","slug":"VMware","permalink":"https://www.liizhi.cn/tags/VMware/"},{"name":"Linux","slug":"Linux","permalink":"https://www.liizhi.cn/tags/Linux/"}]},{"title":"序列之深拷贝/浅拷贝","slug":"序列之深拷贝-浅拷贝","date":"2019-10-22T13:57:35.000Z","updated":"2020-03-14T14:11:34.752Z","comments":true,"path":"2019/10/22/序列之深拷贝-浅拷贝/","link":"","permalink":"https://www.liizhi.cn/2019/10/22/%E5%BA%8F%E5%88%97%E4%B9%8B%E6%B7%B1%E6%8B%B7%E8%B4%9D-%E6%B5%85%E6%8B%B7%E8%B4%9D/","excerpt":"在上周的Python科学计算课上，老师讲到了Python序列的浅拷贝以及深拷贝方面的知识，个人觉得说得比较言简意赅了，对于我这个刚入Python的新手来说，也基本可以避免今后变量的赋值使用错乱的问题。 这里我们简单的将Python中的标准数据类型分为两类： 不可变数据类型：int、float、string、boolean 可变（组合）数据类型：列表（list）、字典（dict）、集合(set) 先举几个例子： 1234567891011121314a = 1 # a为上述定义的不可变数据类型b = aprint('b=&#123;&#125;'.format(b)) # b = 1--------b = 2print('a = &#123;&#125;,b = &#123;&#125;'.format(a,b)) # a = 1,b = 2========c = [1,2,3] # b为上述定义的组合数据类型 d = cprint('c = &#123;&#125;,d = &#123;&#125;'.format(c,d)) # c = [1, 2, 3],d = [1, 2, 3]d.append(4) print('c = &#123;&#125;,d = &#123;&#125;'.format(c,d)) # c = [1, 2, 3, 4],d = [1, 2, 3, 4] 从上述的例子当中看出，在不可变数据类型中，所定义的变量的值在后来改变（这里是b），并不会引起原来赋给它值的那个量的改变（这里是a）；而在组合数据类型中就发生了改变，我们只是将d的值进行了改变，并没有直接改变c的值，最后c的值却也发生了变化。","text":"在上周的Python科学计算课上，老师讲到了Python序列的浅拷贝以及深拷贝方面的知识，个人觉得说得比较言简意赅了，对于我这个刚入Python的新手来说，也基本可以避免今后变量的赋值使用错乱的问题。 这里我们简单的将Python中的标准数据类型分为两类： 不可变数据类型：int、float、string、boolean 可变（组合）数据类型：列表（list）、字典（dict）、集合(set) 先举几个例子： 1234567891011121314a = 1 # a为上述定义的不可变数据类型b = aprint('b=&#123;&#125;'.format(b)) # b = 1--------b = 2print('a = &#123;&#125;,b = &#123;&#125;'.format(a,b)) # a = 1,b = 2========c = [1,2,3] # b为上述定义的组合数据类型 d = cprint('c = &#123;&#125;,d = &#123;&#125;'.format(c,d)) # c = [1, 2, 3],d = [1, 2, 3]d.append(4) print('c = &#123;&#125;,d = &#123;&#125;'.format(c,d)) # c = [1, 2, 3, 4],d = [1, 2, 3, 4] 从上述的例子当中看出，在不可变数据类型中，所定义的变量的值在后来改变（这里是b），并不会引起原来赋给它值的那个量的改变（这里是a）；而在组合数据类型中就发生了改变，我们只是将d的值进行了改变，并没有直接改变c的值，最后c的值却也发生了变化。 这里，基本数据变量的赋值其实就是深拷贝；组合数据类型的赋值就是起了一个别名。 这里先做出组合数据类型中赋值、浅拷贝、深拷贝三种的区别： 直接赋值：其实就是对象的引用（即给对象起一个别名）。 浅拷贝（copy)：拷贝父对象，不会拷贝对象的内部的子对象。 深拷贝（deepcopy):copy模块的deepcopy方法，完全拷贝了父对象及其子对象。 关于内部子对象的概念，下方会再解释。 接下来我们再看一组图（上课ppt图片）： 这里的a = {1:[1,2,3]}字典类型。b = a : 赋值引用，a 和 b 都指向同一个对象。可以看出，a,b此刻都指向同一个对象，所以改变b的内容，就是在改变a,b同时所指向的对象的内容，可以理解成b就是a的一个别名。 这里 a = {1:[1,2,3]} , b = a.copy()，这里就是一种浅拷贝的方式。可以看出a 和 b 是一个独立的对象，但他们的子对象还是指向统一对象（是引用）。所以在这里L,M就是对象当中的一个子对象（[1,2,3]）便是这里的子对象。 举个上述的例子： 12345678910import copya = &#123;1:[1,2,3],'北京':'天安门'&#125;b = copy.copy(a) # b = &#123;1：[1,2,3],'北京':'天安门'&#125;b[1].append(4) b['上海'] = '东方明珠'b['北京'] = '鸟巢'print('输出：a = &#123;&#125;,b = &#123;&#125;'.format(a,b))-----输出：a = &#123;1: [1, 2, 3, 4], '北京': '天安门'&#125;,b = &#123;1: [1, 2, 3, 4], '北京': '鸟巢', '上海': '东方明珠'&#125; b = copy.copy(a) 使得b为单独一个对象，但是它和a的子对象指向统一对象。这里的子对象就是[1,2,3]（列表子对象）。故当改变b中1键对中的值[1,2,3]时，a也会改变（统一子对象)。但向b中添加值时，便不会对a造成影响，因为这是b自身的对象所拥有的值（和a没有关系)。 那么如何拷贝一个a，但对这个拷贝的对象任意操作时，不会对a产生任何的影响呢？答：采用深拷贝。 如图: 从图中可以清楚的看出：深度拷贝, a 和 b 完全拷贝了父对象及其子对象，两者是完全独立的。 123456789101112131415161718import copya = [1, 2, 3, 4, ['a', 'b']] #原始对象 b = a #赋值，传对象的引用c = copy.copy(a) #对象拷贝，浅拷贝d = copy.deepcopy(a) #对象拷贝，深拷贝a.append(5) #修改对象aa[4].append('c') #修改对象a中的['a', 'b']数组对象print( 'a = ', a )print( 'b = ', b )print( 'c = ', c )print( 'd = ', d )--------a = [1, 2, 3, 4, ['a', 'b', 'c'], 5]b = [1, 2, 3, 4, ['a', 'b', 'c'], 5] # 给a起了一个别名b，本质相同，故b和a的变化相同c = [1, 2, 3, 4, ['a', 'b', 'c']] # c中子对象发生了变化 --&gt;浅拷贝d = [1, 2, 3, 4, ['a', 'b']] # a的改变和d无关 --&gt;深拷贝 总结对于组合数据类型： 直接赋值：其实就是对象的引用（别名） 浅拷贝（copy)：拷贝父对象，不会拷贝对象的内部的子对象 深拷贝（deepcopy):copy模块的deepcopy方法，完全拷贝了父对象及其子对象。","categories":[{"name":"Python","slug":"Python","permalink":"https://www.liizhi.cn/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://www.liizhi.cn/tags/Python/"}]},{"title":"Hexo yilia 主题添加相册功能","slug":"hexo-yilia-主题添加相册功能","date":"2019-08-28T10:08:42.000Z","updated":"2020-03-14T18:27:47.398Z","comments":true,"path":"2019/08/28/hexo-yilia-主题添加相册功能/","link":"","permalink":"https://www.liizhi.cn/2019/08/28/hexo-yilia-%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E7%9B%B8%E5%86%8C%E5%8A%9F%E8%83%BD/","excerpt":"当我们使用hexo博客框架中的yilia主题时，在我们这一博客页面中，原作者Litten并未帮我们添加相册这一功能。这时，如果想让我们的博客拥有相册的功能，就需要我们自行添加改变、添加主题中的相关参数。从网上百度了很多，看了许多的博客，还是遇到了一些坑爬不过去。最终，还是请教了一个小伙伴才得以解决。 一、博客页面添加相册首先，打开cmd进入blog的source目录下，创建photos文件夹。 1234E:\\&gt;cd blogE:\\blog&gt;cd sourceE:\\blog\\source&gt;hexo new page &quot;photos&quot;INFO Created: E:\\blog\\source\\photos\\index.md 删除文件夹中的index.md文件，否则最终生成的是一个单纯的页面。也可以直接进入source文件下创建photos文件夹。","text":"当我们使用hexo博客框架中的yilia主题时，在我们这一博客页面中，原作者Litten并未帮我们添加相册这一功能。这时，如果想让我们的博客拥有相册的功能，就需要我们自行添加改变、添加主题中的相关参数。从网上百度了很多，看了许多的博客，还是遇到了一些坑爬不过去。最终，还是请教了一个小伙伴才得以解决。 一、博客页面添加相册首先，打开cmd进入blog的source目录下，创建photos文件夹。 1234E:\\&gt;cd blogE:\\blog&gt;cd sourceE:\\blog\\source&gt;hexo new page &quot;photos&quot;INFO Created: E:\\blog\\source\\photos\\index.md 删除文件夹中的index.md文件，否则最终生成的是一个单纯的页面。也可以直接进入source文件下创建photos文件夹。 二、创建图片存储仓库因为，我们的博客是部署到远端，使得每一个人都能够看到，而图片在远端的展示，可借助于图床。所以，我们可以专门在github上创建一个仓库用于存储图片。仓库的创建就不再一一赘述，只需登录自己的github，new repository即可。这里，我的仓库名为blog-Picture.在创建完远端仓库后，将本地与github上远端仓库关联，这样我们以后才能够将图片推送到远端。远端仓库与本地仓库关联的方法:打开博客文件夹，在此根目录下，使用git ,即 git Bush Here,然后输入 $ git clone git@github.com:chemlez/picture-blog.git 其中clone的仓库换成自己的仓库地址。这样便能使本地与远端关联起立。此刻，会产生一个blog-Picture的文件夹，在此文件夹下分别创建min_photos、photos文件夹。其中，在此photos文件夹下存入一张图片，再将整个内容推送至远端。 $ git add .$ git commit -m “照片存放”$ git push -u origin master 这个时候本地的内容就被推送到了远端。关于git推送远端的用法，可参照廖雪峰的教程。这样后面我们可以用来查看图片的存入地址，来修改我们的ins.js参数。 三、创建相册布局样式在一开始的博客主题clone中，主题yilia并没有相册的版块。但作者Litten的博客样式中添加了这一版块。所以，我们可以参照原作者的格式进行相关的修改即可。其中的样式参照这里–样式参考。下载完之后：1.删除其中所有的.json文件。因为，后面的.json文件是我们自己博客在上传图片时生成的.2.修改index.ejs。这一步很重要，我自己查百度和相关博文时，都没有提到这一步。将其中的href修改成自己的博客地址。当初我就没有修改，最终，显示出来的永远都是原作者Litten的相册. 123 &lt;div class&#x3D;&quot;instagram itemscope&quot;&gt; &lt;a href&#x3D;&quot;https:&#x2F;&#x2F;chemlez.github.io&#x2F;&quot; target&#x3D;&quot;_blank&quot; class&#x3D;&quot;open-ins&quot;&gt;图片正在加载中…&lt;&#x2F;a&gt;&lt;&#x2F;div&gt; 3.修改ins.js文件里的render()函数，按照上面的注释提醒，进行修改。 1234567891011121314&#x2F;&#x2F; 修改这里render()函数：修改图片的路径地址.minSrc 小图的路径. src 大图的路径.修改为自己的图片路径(github的路径) &#x2F;&#x2F; https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ChemLez&#x2F;blog-Picture&#x2F;master&#x2F;photos&#x2F; &#x2F;&#x2F; https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ChemLez&#x2F;blog-Picture&#x2F;master&#x2F;min_photos&#x2F; var render &#x3D; function render(res) &#123; var ulTmpl &#x3D; &quot;&quot;; for (var j &#x3D; 0, len2 &#x3D; res.list.length; j &lt; len2; j++) &#123; var data &#x3D; res.list[j].arr; var liTmpl &#x3D; &quot;&quot;; for (var i &#x3D; 0, len &#x3D; data.link.length; i &lt; len; i++) &#123; var minSrc &#x3D; &#39;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ChemLez&#x2F;blog-Picture&#x2F;master&#x2F;min_photos&#x2F;&#39; + data.link[i]; var src &#x3D; &#39;https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;ChemLez&#x2F;blog-Picture&#x2F;master&#x2F;photos&#x2F;&#39; + data.link[i]; var type &#x3D; data.type[i]; var target &#x3D; src + (type &#x3D;&#x3D;&#x3D; &#39;video&#39; ? &#39;.mp4&#39; : &#39;.jpg&#39;); src +&#x3D; &#39;&#39;; 这里的地址，就可以查看我们第二步所做的工作。打开github，进入blog-Picture仓库后。点击在第二步中上传的照片。然后点击Download，此时的浏览框中的地址就是我们所需要的地址。 四、添加脚本这里添加的python脚本主要是用于处理图片。脚本下载-下载地址.因为，当我们点击相册这一页面时，展示在眼前的是一张张缩略图。而当你需要预览具体的某一张图时，其显示的是一张大图。所以，我们的预览图照片大小是经过压缩处理的（使得页面加载快）。当我们具体看某张图片时，再使用原画质的图片。所以，min_photos和photos两个文件夹分别对应着这两种图片。其中，min_photos就是处理过后的压缩图片，而photos就是我们存放的图片。所以，这里的python脚本主要就做着这样的工作。 将其中的.py文件拷贝至本地仓库blog-Picture文件夹中. 根据脚本文件，图片的命名规则为：2019-10-21_xxx.jpg/png. 将图片empty.png下载放入博客目录下的assets/img文件夹中. 打开tool.py文件,修改def handle_photo():1with open(&quot;E:&#x2F;blog&#x2F;source&#x2F;photos&#x2F;data.json&quot;, &quot;w&quot;) as fp: 将其中的的地址，换成你将要生成data.json的位置，就是在第一步中，我们删除的.json文件夹的目录地址。每次，进行tool.py脚本时，都会产生data.json文件，用于存储我们图片的信息。 五、运行1.首先将用于测试的图片名改成上述的命名规则的名字,推送至github远端，进行修改.2.打开终端命令窗口cmd. 1234567输入：cd blog-Picture &#x2F;&#x2F;用于进入blog-Picture文件夹python tool.py &#x2F;&#x2F;python脚本文件的运行第二句的运行这里可能会报错 &#96;no module named PIL&#96;然后输入：pip install pillow可能出现权限不足的情况，按照下方出现的英文，加上权限进行下载。即：一路按照下方的英文,加权限进行下载. 3.hexo s.预览查看。这里我将video功能隐去了，最初的photos旁边还有一个video功能。4.在最初的photos下载中，有个videos.ejs文件，如果想引入一些视频，可将其中的链接即src，视频名进行修改. 12345678910&lt;center&gt; &lt;h1&gt;指弹_女儿情&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;&lt;hr&#x2F;&gt;&lt;center&gt; &lt;div class&#x3D;&quot;video-container&quot;&gt; &lt;iframe height&#x3D;&quot;80%&quot; width&#x3D;&quot;80%&quot; src&#x3D;&quot;https:&#x2F;&#x2F;player.youku.com&#x2F;embed&#x2F;XMjUzMzY4OTM3Ng&#x3D;&#x3D;&quot; frameborder&#x3D;0 allowfullscreen&gt;&lt;&#x2F;iframe&gt; &lt;&#x2F;div&gt;&lt;&#x2F;center&gt;&lt;hr&#x2F;&gt; 如果不想用这一功能，将以下标签注释. 1&lt;a class&#x3D;&quot;photos-btn&quot; href&#x3D;&quot;&#x2F;photos&#x2F;videos.html&quot;&gt;Video&lt;&#x2F;a&gt; 六、总结 每次将需要上传的图片，放入到blog-Picture中的photos文件夹.图片的命名一定要遵循上述说的命名规则.注意：如果想让多张图片归类在页面中的某一个年、月份下，必须使得日期一模一样，只能修改xxx。如果命名中，年、月相同，而日期不同便会在相册页面额外生成一个list，其表头相同。 cmd命令窗口进入blog-Picture,再进行python tool.py，运行脚本. 将图片推送到github远端仓库，产生链接. hexo s 进入本地窗口预览，没有问题后：123hexo clean &#x2F;&#x2F;清除页面缓存hexo g &#x2F;&#x2F;用于生成改动的文件hexo d &#x2F;&#x2F;部署到远端网站 最终效果 参考文献[1] hexo Yilia 主题如何添加相册功能:https://www.jianshu.com/p/a9f309aaa0e0[2] hexo yilia 主题如何添加相册:https://blog.csdn.net/qq_40651535/article/details/95061281[3] Hexo+Github实现相册功能:http://lawlite.me/2017/04/13/Hexo-Github%E5%AE%9E%E7%8E%B0%E7%9B%B8%E5%86%8C%E5%8A%9F%E8%83%BD/","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://www.liizhi.cn/tags/hexo/"}]}]}